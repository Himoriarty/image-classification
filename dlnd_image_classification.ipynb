{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'zeors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5339d1feebc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfile_ssq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar10_dataset_folder_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mssq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mssq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_ssq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mx_ssq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'zeors'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "import numpy as np\n",
    "\n",
    "cifar10_dataset_folder_path = '/media/moriarty/Life without Work/cai'\n",
    "\n",
    "\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "ssq = '/ssq'\n",
    "ssqblue = '/ssqblue'\n",
    "\n",
    "file_ssq = open(cifar10_dataset_folder_path+ssq,'r')\n",
    "ssq = file_ssq.readlines()\n",
    "x_ssq = np.zeors(len(ssq),33)\n",
    "\n",
    "for i,line in enumerate(ssq):\n",
    "    line = line.split('\\t')\n",
    "    for n in line:\n",
    "        x_ssq[i,int(n)-1] = 1\n",
    "        \n",
    "\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHF9JREFUeJzt3UmPZOl1HuAvxsyMrKzKqsqau6rY\nA5vNbropkjJJmYIsUIBXWtn+BV7YO/8Yr73wymtDNAwIggwSMEmBNMeW2Wz2VOzumquyco6M2Qtt\nzI2Bc5gChYPn2Z88Ed+9cd+8q7ezWq0aAFBT9w/9AQCAfzyCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/T/0B/jH8l/+\nw79fZebGx9PwTK+f+3+pc/tGeGZvtJHa9faFYWruk1/+LDzznR/+PLVrbzILz/R6ybPvdFJzg7X1\n8MylKzupXec34t/t83eupHb9+be+Hp6Zz+LXq7XWnu0fpeYGWxfDM+9+8NvUrr/97g/jQ8nnwNog\nN3dhMAjPDPuL1K5p4lrPZ7nfWFstU2NrvbXwzMkq/rxvrbUXp/F46eZ+Lu073/+75EH+P7t/3z8A\nAPzTJegBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl\n2+te3P84NddfxJuTBv1UUV67v5qEZ94f5yqQ3v7iK6m55TT+Ga/t5NraNlLfLXf22fa6k0n8PPZ3\nX6R2HXXiTWOT03Fq15e/+o3wzOzkNLXr2fPceVxbjzc3LqcHqV0ba/H7atlyrWtXt86l5r70ymvh\nmadP7qd2jceH4Zmjo1xLYevGW/laa22tPw/P3Lx+IbVrNrwanvngV/dSu86CN3oAKEzQA0Bhgh4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZUpuPT9dScyfj/fDMsJMr\n92iLeKFCtzNMrXr228epuZ88+Cw88+snudKS1SReSpEtp1lfX0/NzebxopnWzf0/vb4Rv4f3xrli\nlR+983545sblXCHIZJ67ZpkCo7XkE24wSHzG3NG3L7z6amruc3fuhme2t0apXY8e3gvPLGe55+K5\nizdSc4tBvPRotJYr3rm5Ey8i+rSXO/uz4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdeNeriFrtxtvJ+ssJqldl/vx4z93/mJq1+lxvJWv\ntdb2DuPf7eB0ltq1Spz9YpFok2ut9ZKfsZ/533gWb11rrbXjafzsz61yu370i1+GZ15/7bXUrjde\nvZOa6w/j7V+f+1yuGe54OQjPPH74NLXr4HCcmmvrm+GRP/6zt1Orfv7j74VnxvN4G2VrrR3Oci1v\nz4/jz8ZL41zD3q3eYXjm9Cjb2vj780YPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAw\nQQ8AhQl6AChM0ANAYYIeAAorW2qz1tlNzd0YxYsYtlu8AKO11i5d3AjPfLyKlym01trmxjI1t9aJ\nl6SMOrnbara5Fp+Z58ppTie5IqJF4n/jjVGupGO4Fr+vrt++kdp186Xb4ZlnR7lCkEcHuRKXb3zj\n6+GZ3cePUrv+9b/5Vnjmf/z3v07t+uEP/i41d+dLXw3PfPvtr6V2fXj/o/DMx9//cWrX/nQrNXc0\njz/jvvjP42fYWmvj2YvwzM7OemrXWfBGDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrhZu6rvbJ1NTzz8iq368Iw0Wa0/1lq12g73gzXWmvH\nw5PwzHKwSO364z+KN0lduxq/Xq219tEHH6TmPv3kfnim28u1G67m8Xa49W7u7P/kG/Gzfxq/NVpr\nrf3oe99Nzb333p3wzGKc/JCbF8Mje8e5RsSjWe5964OHz8Mzx8teatfxPP4Zn+zlzmOyfi419/m7\nr4Rntq/dTO16+jx+9t/+9lupXWfBGz0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIE\nPQAUJugBoDBBDwCFCXoAKEzQA0BhZdvrjqa5xrALvc3wzOzZi9SuT/fiTWh/+uU3UrvG0+PU3K1l\nfGZ9tErt+uZ2/OzfvLKT2nWyzH3GZ2vxFsCT/dz9sZjGZ/rTw9Suu598HJ7Z2Jundl26sp2am/39\nz8Iz2ebAH/7q3fDMew8epHadznMtb/c/iTdZPnn+NLXr61/5Znjm7vbt1K7/9F//W2puOn4UnvnJ\nj5+ldj1+/GF45qt/kXt2nwVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgsLKlNld666m5W60Xnjl/fiu16+cv4qUULyb7qV13r99Izf3bJy+HZwYHuQKd\ny+/Hz2Ptw4epXYvlLDX3uU58ZrBIDLXWuv34Pbzo5EpcJj/6aXjmQrKMZbkTLy9qrbXFPNGwdLBI\n7TrfOxeemRzn7vtL8UdOa6210Wocnjl49NvUrltffD08s7WZewZ//dVbqbkn+/EWqEdHJ6ldJye7\n4ZmP3n8/tesseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGg\nMEEPAIUJegAorGx73Rtbo9Tc5vNn4ZleN9Gq1Vp7/aWXwjOHj5+mdrVVrkHtVmcVnhkNc7t6iUao\nzjL++VprLd5z9Q8m3cT/xsO11K7BKv7d+pmGt9baoBtv85tt5WrXVie51rv5JH4ei5a7F69143fI\ntzdyrXzTzjA1t7h5LTyzfu9eatdJ5iMmWz3feuO11NyNk/g1uzGbp3a9/urN8MxrO/FGxLPijR4A\nChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFFa21Gb3wUep\nuck8XoIx7uWKRE4uxEsONk7i5SOttXb67oepuUVvEZ6Zb+Zuq24vXkqxlixx6bT11Nw8UQ60WOY+\n42owiM+kNuXm+ldfSe3a2su9X5wmLtn07sXUrovzo/DM5mmuKmm+lytWOXqyH545efD91K6H//sX\n4Znzb72e2vX8Ua64azq6FJ6Zj1Or2snzF+GZg0G2Suv3540eAAoT9ABQmKAHgMIEPQAUJugBoDBB\nDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtdc+P9lJznx6fhmfmy1z71LBzPTwz\nuriT2vV8fJiau95bC89snOb+f1wcxJv5JtNcm1/byZ3j5uuvhWdOE01orbV29OwgPLO2jLfrtdZa\nbzIJz0ye5u6ptpZrlOtsx9se+51cn9/yIP4c2Hgr1+bXhvHv1Vproyfx6rXj+/dTu/Z+/UF4ZvnJ\n49SurUtbqbnd7XhL5PNHud/mwyefhWdeHt5I7ToL3ugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCY\noAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKK9te9+I03j7VWmuPTuJtRrOD49SunWtXwjOr\n21dTu9Yu5hqh1g7izXz9B09Tu6ZHJ+GZoxZvrGqttcW5jdTc4O6d8Ey/s0jt2tyOn8fsN5+kds0S\nLYCn3Vxz4NafvZmaO9l7Fh9679epXW2eeAd6mPh8rbXJMte0Obh+Mzxz/V9+M7VrbaMXntn9zYep\nXdsn8V2ttXbhbrxp85NHuYa9jV68FXEwGKZ2nQVv9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLKlNrdvv5Sa6358PzyzMU6taotpvBhhrTNI7XpxfJCa\n+8Gnn4Vnbp4epna90eIHOUmUsbTW2vh+/Dq31tr0p7+K72rx69xaa51bt8Izp69fT+06mY/CM2+/\nmiunOe6eS82NH9wLzwz3c+VW8/PxApLpJ8lCoce5UqzB1SfhmZNruVKswaUL4ZmLf/HV1K69Tx+m\n5rZ34mU4Xz13N7Xrb/7Xi/DM2na8xOyseKMHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0\nAFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGx73fWb11Jzh/efhWdGFzupXa2zFh4ZdHO7Hj57npr7\nz7/4P+GZL1zOtZP9x/XN8Mwo+a/q6vgoNbf7Try9bvdKvPmrtdY+msRbzabJprybr98Mz9y5mPte\n04ePU3PnEq1mneU0tasdxn9na92N1KqD8UlqbvHRR+GZ1YNHqV0vtuLPqs0v5BpEb778amru9FH8\nvroyij9zWmvtK196LTxz++XceZwFb/QAUJigB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT\n9ABQmKAHgMIEPQAUJugBoLCypTb7ixepuf5qPzwz6OeOcdqLF5DszcepXbvjXNnJfBX/bgeDXLnH\n/cEoPLO9mqd2Tbu5udVqEp7ZX+ZKSz57Ei+1Od9dT+16kbhkf3X/r1K7vnDrVmru1Uvx73Z57Xpq\n1/G9++GZxTh+vVprbbXI3YsvXjxN7Mo9B6br8VKb2X68IKy11qa/fD81N0oUOk3WB6ldd998Kzwz\ne/Db1K6z4I0eAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9\nABQm6AGgsLLtdcPVMjXXX87CMzvdXAPStBdvrerPpqldJ6e587h15Up45qWXb6d23T9KNPOtcm1c\nw2RrVWce/8lMl/HGu9Zau3F5JzzTzxWhtYOnj8Izq91cK9+D57mWt/3RMDxzZxL/PbfWWvdZvL2u\njXOH353n3rfG8/g5nixyz49VohVxNO6kdj28/1lqbtSJ7zue567Z9iQ+t/P266ldZ8EbPQAUJugB\noDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAorGypzcZ4lJp7ML8Q\nnrnaPU3tujjeC8/0nzxM7ZofvkjNffHNl8Mzd77w+dSu3V+8F5650emldrVBrgxnsIr/b7xxlCtx\n6bf4ZxyNNlK7fvPhvfDMznHuPeGVz11KzX02jBfUPP4g93vZONwNz3TmuXuqs8jdw6eJUqxpN3fN\npsfxXbuLw9Su0eh8au5wGi+POp7krtnu/cfhmf6d66ldZ8EbPQAUJugBoDBBDwCFCXoAKEzQA0Bh\ngh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGFl2+v2j+NNV6219t39eEvT/HJqVfvW\nchqe2XjyKLVrfXaSmvvK174dnrl5+7XUru/86J3wzP4k1xy46Ofuj1miLW9j1UntOv0sfq17l3LN\ncK9c3AnPnC72U7v6m8PU3Nt/+vXwzG680Owf5n7yJDwzWeaa0Jb9tdTcOHFfbW4mH1Ybm+GR8TDX\nyre8fDE1d9ri+x49jbcUttba/t6z8MyLX7+f2vWXqanf5Y0eAAoT9ABQmKAHgMIEPQAUJugBoDBB\nDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgsLLtddODB6m5D54/Ds+MZ7k2ru2X4o1h\nXx7kWte2+vFWvtZae/n27fDM+XO5BrXJIt7mNzmJz7TW2nCwSM2druL7ht3c/TGcxq/ZeDfXxtXt\nxx8Fy16ure3x81wD44t3fxWeGa3nGtQO18/FZzZGqV2Tc1upuePj4/DMaCf329ydxlsiD+e531h3\nNk7NPXx0FN+1Hm/la621g1n8ObB5kGt7PAve6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DC\nBD0AFCboAaAwQQ8AhQl6AChM0ANAYWVLbf7V3VxZwdPdeJnFjz8+Se36m3vxkoONV3Lfa3RuLTW3\n1YsXdcwO4wUYrbW26MRLMI4nuV3rvdytv+gl/jfu5P6fXnbjc7vH8WKP1lpbncYLdIbHubOf7eWK\niFYffhKeGSXfZaaj8+GZd+aT1K57z56k5taX8ZnhMlcYM1iP/146s05q1+lerpjpeBUvB+qfG6R2\nLQbx73b34nZq11nwRg8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFBY2fa612/mvtq/G90Jz9xeu5/a9T/fizeN/e29WWrXH929mZo7+vDj8Mxe8v/H\n3jJex7U3zTUHXhnFm65aa22x6oVnZsvcNXu6ip/Hs1G8fbG11k778fa6rU7uN7Z5IXf2y2n8M7bn\nB6lda2vxlsjPTnPNcM8Xq9Tc9UG8eW20mbs/tjbj57Ea59oNn01z59jvxZ8Fvd3c8+NLq2F45txh\n7jlwFrzRA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DC\nypbaTJJlJ5fWO+GZP3l9J7Xr2XG8tOQn9/dTu959/CI19/lEUcd0mLutVsv4/52Hp5Pcrkm8lKK1\n1gbr8e+2WuZKS1pibmNtPbXqcBUvIDm4cy216/Jbb6TmevGfS3vnr7+X2nU7cV+9dPFKalebTFNj\n6/34gezPcoUxx8/jz9PryYKlmzuXU3PDbvy3OdjNPU/vHsYLyW5vb6d2nQVv9ABQmKAHgMIEPQAU\nJugBoDBBDwCFCXoAKEzQA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIWVba/r9HJfrTOPt1bd\n2M41hv2Lly+EZw6m8Zax1lq7t5dr8zvpxdv8rt6+ndrVG47CM6fzXDPc6eFhaq4/W4RnhoON1K74\n3dHa/PHT1K7zi3l4ZnKQu6d2Z4kautba9sWL8ZlO7l1mcBr/brc2N1O7hsn3rc7mWnxmkPuM3aN4\nw961fvz33FpriQLR1lpr3Un8t3mSfA5c6MXvj1fv5HLiLHijB4DCBD0AFCboAaAwQQ8AhQl6AChM\n0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91qlatAWi0T7WTLeONda629eSl+\n/E9vnEvtOp7kPuN8HG/L27l8JbVr/Vy8r21vmWuvm01nqbl5Ym7SyzUOdju98Mz55L/umV6t6cF+\nbtlp7jxWj56EZ15quefAoBdv89sa587jai/Xbvgi0Ui5thVvAGytteUsfmPNT/ZSuw4muVbERHld\nW06OU7tuvHk1PPPyndxz8Sx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DC\nBD0AFCboAaAwQQ8AhZUttVl2cv/DLFq8SKTNcwUpF/rxwo2v3N5J7Xp+uJuamz5+GJ6ZHeeKIoab\n8XKP0+R1nq1yc91l/FovZom2jdZaZxG/P+bJ85gOMuUv8eKX1lrrzHPnsegN40PdXKnNYh7/bqtk\nWc/6YpCaW82m4ZlH67mimdla/OyXa6lVbbCZO4+Tk/h5DFfL1K4rd66HZ9b7ifv3jHijB4DCBD0A\nFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKKxse91wYzM1\n11sfhWeme0epXZlWs5vb8c/XWmv/bD/XrPXu3uPwzKMHn6R2HYwPwjNHy1z71Gk39z/uYLkKz8xX\nuba27ir+8zzu5NraTlbxuX7yPWE5yV2z5SR+D3eS7XUtcZ1P+7nrvEw05bXW2nHmM65NUrtaN/7d\n1ge5+rrlIt5C11prm8v4d3vt2lZq18Vh/OxPnueaA3Of8Hd5oweAwgQ9ABQm6AGgMEEPAIUJegAo\nTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaAwQQ8AhZUttWndXmqs0xmEZ/obqVXttDsLzwwSZQqt\ntXbnRq4M5+PP4gUT08lxatdiGd+1N88VYDzr5G79rV78vuqscteskyio2c/1xbRH03hpSbeTe0/o\nJQp0srJvMoMWv86Pl/Hfc2ut7bdcGc5R4lrfSpb8bCcKuHq7h6ld1/rrqbmv3b4ennn1du7hPRrH\ni8wmybIepTYAwP+XoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCbo\nAaAwQQ8AhdVtr1vm/oeZjE/CM9k2rk6iSWo1zTVkndvcTM3tnI83Lu0+fZLadfgoPrffy13nHySb\nxi4miujOJxoRW2ttM9FeN+vmmvIO5vG502TrWra7rteNX+thom2wtdZGqU+Z29Xv5CoHR4lrvZzN\nU7umi/h5bCTvjwvncp+xzQ7CI0cvcmd/cD7+m+7Mc8+cndTU7/JGDwCFCXoAKEzQA0Bhgh4AChP0\nAFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUFjZ9rrFMtfitUrMdZINasP+MDyz\nGucakFruONrVzfhn/Ok7f5/a9fzB0/DMvJO7hZ8mO9QO5vE2v9Ei2U6W+IhryXtxNYxf526iTa61\n1jqJVr7WWuv3441hi1WynWwR/53N57m2tlXyMw4zx59sr1sm7qtuP/fQWbbcM27vaC8801vlzmOt\nuxWe6Sz/cHHrjR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DC\nBD0AFFa21KY7iBdgtNbaINHD0EkWxnR6ieNf5IozFsdHqbkbW6PwzOVB7jMOTsfhmfPLXEHKaSf3\nP243MTfv50pLjpfxuXHyXmyJEpfePLeskywU6iYKhVarZLlVJ372uW/V2qDTy80lnh8byfv+XGJs\ns5N8DuTGWmvxwcn4OLUp8zgddePP0rPijR4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNAD\nQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwuu11/dxX660S//uscu1kLdVel2vl63dz3VrnOvHGsD97\n62Zq1/5JfNfPPnmW2vVsMk/NnS7jbWiTZK/ZMnF/LJP/uy8S36ubrG3sJGveut1sNV9cL9Hy1k9+\nvI1u7lk16safBVv93OFvdePPuMvJdBklb5BBi/+mh8l7arWI7zpNtHOeFW/0AFCYoAeAwgQ9ABQm\n6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCboAaCwsqU2bbieHIyXFXRWyTaLRPHO\nfD5LrVomL3WmvOHGKLWq/eWXb4Vnrg1yhUIfPD5IzT0+jp//i3mupON02QvPTJK34rwTv86rRPFL\na611e/Hv1VprvcRcsj+nDRIlP/1kt9VmptyqtbaWOP+1Tu5Dnu8twjMXkwU6m73cfbU+iJ9jP3cr\nttks/hw46cTP8Kx4oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCbo\nAaAwQQ8AhQl6ACiss8o2rwEA/+R5oweAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJig\nB4DCBD0AFCboAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQ\nA0Bhgh4AChP0AFCYoAeAwgQ9ABQm6AGgMEEPAIUJegAoTNADQGGCHgAKE/QAUJigB4DCBD0AFCbo\nAaAwQQ8AhQl6AChM0ANAYYIeAAoT9ABQmKAHgMIEPQAUJugBoDBBDwCFCXoAKEzQA0Bh/xfkBwlH\nN40TWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda4583ec50>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_normal = np.zeros(x.shape)\n",
    "    x_min = 0\n",
    "    x_max = 255\n",
    "    rangea = 0\n",
    "    rangeb = 1\n",
    "    x_normal = (x-x_min)/float(x_max-x_min)*rangeb +rangea\n",
    "   \n",
    "    return x_normal\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    one_hot_array = np.zeros([len(x),10])\n",
    "    for n,label in enumerate(x):\n",
    "        one_hot_array[n][label] = 1\n",
    " \n",
    "    return one_hot_array\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = tf.placeholder(tf.float32, [None, image_shape[0],image_shape[1], image_shape[2]],name='x')\n",
    "    return x\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    y = tf.placeholder(tf.float32, [None, n_classes],name='y')\n",
    "    return y\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    return keep_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    xshape = x_tensor.shape\n",
    "    \n",
    "    wc = tf.Variable(tf.truncated_normal((conv_ksize[0],conv_ksize[1], int(xshape[3]),\\\n",
    "                                          conv_num_outputs),mean=0.0,stddev=0.04))\n",
    "    b = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, wc, strides=[1, conv_strides[0],conv_strides[1], 1], padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, b)\n",
    "    conv_layer = tf.nn.max_pool(\n",
    "                                conv_layer,\n",
    "                                ksize=[1,pool_ksize[0],pool_ksize[1],1],\n",
    "                                strides=[1,pool_strides[0],pool_strides[1],1],\n",
    "                                padding='SAME')\n",
    "                   \n",
    "    return conv_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    xshape = x_tensor.shape\n",
    "    x_flatten = tf.reshape(x_tensor, [-1, int(xshape[1]*xshape[2]*xshape[3])])\n",
    "    \n",
    "    return x_flatten\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    wfc = tf.Variable(tf.truncated_normal((int(x_tensor.shape[1]),num_outputs),mean=0.0,stddev=0.01))\n",
    "    bfc = tf.Variable(tf.zeros(num_outputs))\n",
    "    fc = tf.add(tf.matmul(x_tensor, wfc), bfc)\n",
    "    \n",
    "    \n",
    "    return fc\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    wout = tf.Variable(tf.truncated_normal((int(x_tensor.shape[1]),num_outputs),mean=0.0,stddev=0.1))\n",
    "    bout = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    out = tf.add(tf.matmul(x_tensor,wout),bout)\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    convmax1 = conv2d_maxpool(x, 32,  [4,4],[1,1],[2,2], [2,2])\n",
    "    convmax1 = tf.nn.dropout(convmax1,keep_prob)\n",
    "    convmax1 = tf.nn.relu(convmax1)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor\n",
    "    flatten_layer = flatten(convmax1)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc1_layer = fully_conn(flatten_layer, 64)\n",
    "    fc1_layer = tf.nn.dropout(fc1_layer, keep_prob)\n",
    "    fc1_layer = tf.nn.relu(fc1_layer)\n",
    "\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out_layer = output(fc1_layer, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input([32,32,3])\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "   \n",
    "    session.run(optimizer, feed_dict={\n",
    "        x:feature_batch,\n",
    "        y:label_batch,\n",
    "        keep_prob:keep_probability\n",
    "    })\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={\n",
    "        x:feature_batch,\n",
    "        y:label_batch,\n",
    "        keep_prob:1.\n",
    "    })\n",
    "    valid_acc = session.run(accuracy, feed_dict={\n",
    "        x:valid_features,\n",
    "        y:valid_labels,\n",
    "        keep_prob:1\n",
    "    })\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                \n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.0793 Validation Accuracy: 0.305600\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.9347 Validation Accuracy: 0.392400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.8561 Validation Accuracy: 0.415400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.7529 Validation Accuracy: 0.437600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.6755 Validation Accuracy: 0.433200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.6538 Validation Accuracy: 0.455800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.5119 Validation Accuracy: 0.456000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.4959 Validation Accuracy: 0.475200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.3975 Validation Accuracy: 0.476600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.3058 Validation Accuracy: 0.487600\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.2635 Validation Accuracy: 0.499200\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.1963 Validation Accuracy: 0.496400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.1400 Validation Accuracy: 0.500600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.0832 Validation Accuracy: 0.508000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.0425 Validation Accuracy: 0.512800\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.0158 Validation Accuracy: 0.517400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.9948 Validation Accuracy: 0.516000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.9701 Validation Accuracy: 0.521000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.9592 Validation Accuracy: 0.535800\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.9460 Validation Accuracy: 0.528400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.9025 Validation Accuracy: 0.533000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.8780 Validation Accuracy: 0.535600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.8585 Validation Accuracy: 0.535200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.8042 Validation Accuracy: 0.542800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.8218 Validation Accuracy: 0.532400\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.8362 Validation Accuracy: 0.532200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.7709 Validation Accuracy: 0.540800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.7768 Validation Accuracy: 0.533400\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.7149 Validation Accuracy: 0.542600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.7381 Validation Accuracy: 0.541000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.7297 Validation Accuracy: 0.550000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.6954 Validation Accuracy: 0.544800\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.6793 Validation Accuracy: 0.535000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.6525 Validation Accuracy: 0.543800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.6603 Validation Accuracy: 0.546400\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.6233 Validation Accuracy: 0.540400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.6494 Validation Accuracy: 0.547200\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.6390 Validation Accuracy: 0.542200\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.5988 Validation Accuracy: 0.544600\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.6010 Validation Accuracy: 0.542000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.6207 Validation Accuracy: 0.547600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.5924 Validation Accuracy: 0.540400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.5964 Validation Accuracy: 0.547400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.5889 Validation Accuracy: 0.552400\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.5867 Validation Accuracy: 0.543800\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.5252 Validation Accuracy: 0.548200\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.5478 Validation Accuracy: 0.541800\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.5853 Validation Accuracy: 0.546400\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.5119 Validation Accuracy: 0.550000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.5190 Validation Accuracy: 0.544600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2238 Validation Accuracy: 0.222600\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.1252 Validation Accuracy: 0.267000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.8639 Validation Accuracy: 0.276600\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.9269 Validation Accuracy: 0.298400\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.9373 Validation Accuracy: 0.321600\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.1271 Validation Accuracy: 0.348800\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.8891 Validation Accuracy: 0.352800\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.6956 Validation Accuracy: 0.364800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.7136 Validation Accuracy: 0.372400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.7677 Validation Accuracy: 0.383200\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.0157 Validation Accuracy: 0.387600\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.8152 Validation Accuracy: 0.390600\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.5771 Validation Accuracy: 0.388200\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.6343 Validation Accuracy: 0.401600\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.7087 Validation Accuracy: 0.411000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.9903 Validation Accuracy: 0.414600\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.7554 Validation Accuracy: 0.413200\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.5414 Validation Accuracy: 0.414800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.6034 Validation Accuracy: 0.415800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.6879 Validation Accuracy: 0.423200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9231 Validation Accuracy: 0.426600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.6887 Validation Accuracy: 0.434800\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.5053 Validation Accuracy: 0.427400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.5819 Validation Accuracy: 0.432800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.6438 Validation Accuracy: 0.434000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.8926 Validation Accuracy: 0.439000\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.6430 Validation Accuracy: 0.440600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.4717 Validation Accuracy: 0.431000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.5756 Validation Accuracy: 0.445000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.6356 Validation Accuracy: 0.439000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.8006 Validation Accuracy: 0.451200\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.6064 Validation Accuracy: 0.459200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.4419 Validation Accuracy: 0.448600\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.5433 Validation Accuracy: 0.457400\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.5576 Validation Accuracy: 0.459800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.7645 Validation Accuracy: 0.465400\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.5590 Validation Accuracy: 0.467600\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.3546 Validation Accuracy: 0.465000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.5028 Validation Accuracy: 0.474600\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.5495 Validation Accuracy: 0.467000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.7337 Validation Accuracy: 0.477600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.5431 Validation Accuracy: 0.485400\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.3453 Validation Accuracy: 0.478800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.4943 Validation Accuracy: 0.481800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.5479 Validation Accuracy: 0.476400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.6869 Validation Accuracy: 0.491800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.4932 Validation Accuracy: 0.486600\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.2735 Validation Accuracy: 0.497800\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.4717 Validation Accuracy: 0.498000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.5298 Validation Accuracy: 0.493400\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.6238 Validation Accuracy: 0.501000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.4226 Validation Accuracy: 0.490600\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.2510 Validation Accuracy: 0.498800\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.4761 Validation Accuracy: 0.503200\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.5142 Validation Accuracy: 0.493600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.6171 Validation Accuracy: 0.501400\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.4126 Validation Accuracy: 0.503000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.2316 Validation Accuracy: 0.508600\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.4505 Validation Accuracy: 0.507800\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.4734 Validation Accuracy: 0.508800\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.5859 Validation Accuracy: 0.515000\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.3657 Validation Accuracy: 0.507400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.1957 Validation Accuracy: 0.514600\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.4396 Validation Accuracy: 0.507800\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.4520 Validation Accuracy: 0.510800\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.5742 Validation Accuracy: 0.514400\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.3383 Validation Accuracy: 0.517800\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.1456 Validation Accuracy: 0.516600\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.4166 Validation Accuracy: 0.516800\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.4518 Validation Accuracy: 0.519000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.5259 Validation Accuracy: 0.516800\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.3265 Validation Accuracy: 0.514000\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.1433 Validation Accuracy: 0.523800\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.4094 Validation Accuracy: 0.524400\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.4328 Validation Accuracy: 0.516600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.5399 Validation Accuracy: 0.529400\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.3096 Validation Accuracy: 0.525400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.1141 Validation Accuracy: 0.526600\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.3837 Validation Accuracy: 0.523400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.4122 Validation Accuracy: 0.521200\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.5320 Validation Accuracy: 0.516200\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.2884 Validation Accuracy: 0.522400\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.1218 Validation Accuracy: 0.528600\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.3902 Validation Accuracy: 0.528600\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.3623 Validation Accuracy: 0.530400\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.4602 Validation Accuracy: 0.534600\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.3035 Validation Accuracy: 0.527400\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.0973 Validation Accuracy: 0.527800\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.3593 Validation Accuracy: 0.533200\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.4012 Validation Accuracy: 0.524000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.4970 Validation Accuracy: 0.519400\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.2814 Validation Accuracy: 0.526000\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.1010 Validation Accuracy: 0.521800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.3692 Validation Accuracy: 0.523800\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.3743 Validation Accuracy: 0.525600\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.4888 Validation Accuracy: 0.529000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.2598 Validation Accuracy: 0.529000\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.0638 Validation Accuracy: 0.531400\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.3746 Validation Accuracy: 0.521000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.3640 Validation Accuracy: 0.525600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.4596 Validation Accuracy: 0.533200\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.2471 Validation Accuracy: 0.527000\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.0687 Validation Accuracy: 0.527400\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.3531 Validation Accuracy: 0.534600\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.3457 Validation Accuracy: 0.533400\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.4478 Validation Accuracy: 0.537800\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.2270 Validation Accuracy: 0.535200\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.0251 Validation Accuracy: 0.544000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.3481 Validation Accuracy: 0.535600\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.3476 Validation Accuracy: 0.525800\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.4584 Validation Accuracy: 0.531200\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.2314 Validation Accuracy: 0.533600\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.0359 Validation Accuracy: 0.539000\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.3367 Validation Accuracy: 0.538800\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.3246 Validation Accuracy: 0.532200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.4027 Validation Accuracy: 0.541400\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.2335 Validation Accuracy: 0.529400\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.0500 Validation Accuracy: 0.542000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.3554 Validation Accuracy: 0.532800\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.3277 Validation Accuracy: 0.540600\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.4138 Validation Accuracy: 0.536400\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.2007 Validation Accuracy: 0.534800\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.0209 Validation Accuracy: 0.542400\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.3118 Validation Accuracy: 0.549800\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.2957 Validation Accuracy: 0.534600\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.3966 Validation Accuracy: 0.540400\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.2069 Validation Accuracy: 0.540600\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.0024 Validation Accuracy: 0.542000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.3045 Validation Accuracy: 0.542400\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.3143 Validation Accuracy: 0.531200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.3776 Validation Accuracy: 0.540600\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.1976 Validation Accuracy: 0.536800\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.0380 Validation Accuracy: 0.539200\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.3168 Validation Accuracy: 0.529800\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.3065 Validation Accuracy: 0.536400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.3750 Validation Accuracy: 0.541400\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.1786 Validation Accuracy: 0.536200\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.0244 Validation Accuracy: 0.539200\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.2925 Validation Accuracy: 0.542400\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.2837 Validation Accuracy: 0.534800\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.3441 Validation Accuracy: 0.546400\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.1923 Validation Accuracy: 0.536800\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     1.0018 Validation Accuracy: 0.547000\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.2827 Validation Accuracy: 0.544400\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.3106 Validation Accuracy: 0.538600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.3224 Validation Accuracy: 0.542200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     1.1526 Validation Accuracy: 0.545800\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.9841 Validation Accuracy: 0.550600\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.2586 Validation Accuracy: 0.547800\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.2817 Validation Accuracy: 0.542000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.3565 Validation Accuracy: 0.540200\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.1598 Validation Accuracy: 0.537800\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.9857 Validation Accuracy: 0.544400\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.2466 Validation Accuracy: 0.552000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.2804 Validation Accuracy: 0.541800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.3293 Validation Accuracy: 0.542600\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     1.1506 Validation Accuracy: 0.547200\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.9762 Validation Accuracy: 0.549200\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.2574 Validation Accuracy: 0.547400\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.2700 Validation Accuracy: 0.535600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.3680 Validation Accuracy: 0.539600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     1.1462 Validation Accuracy: 0.545000\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.9883 Validation Accuracy: 0.544800\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.2989 Validation Accuracy: 0.536400\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.2597 Validation Accuracy: 0.545600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.3414 Validation Accuracy: 0.545800\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     1.1712 Validation Accuracy: 0.531800\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.9878 Validation Accuracy: 0.542000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.2692 Validation Accuracy: 0.545000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.2696 Validation Accuracy: 0.541200\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.3469 Validation Accuracy: 0.549800\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     1.1563 Validation Accuracy: 0.545400\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.9858 Validation Accuracy: 0.548000\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.2589 Validation Accuracy: 0.545200\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.2134 Validation Accuracy: 0.543600\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.3362 Validation Accuracy: 0.548800\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     1.1471 Validation Accuracy: 0.545200\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.9843 Validation Accuracy: 0.546600\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.2517 Validation Accuracy: 0.545200\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.2149 Validation Accuracy: 0.547600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.3248 Validation Accuracy: 0.548000\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     1.1648 Validation Accuracy: 0.539800\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.9382 Validation Accuracy: 0.552800\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.2478 Validation Accuracy: 0.549800\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.1988 Validation Accuracy: 0.541000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.2822 Validation Accuracy: 0.551000\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     1.1708 Validation Accuracy: 0.544600\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.9692 Validation Accuracy: 0.553600\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.2204 Validation Accuracy: 0.555600\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.2408 Validation Accuracy: 0.536000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.2883 Validation Accuracy: 0.549600\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     1.1646 Validation Accuracy: 0.549200\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.9512 Validation Accuracy: 0.553800\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.2550 Validation Accuracy: 0.543800\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.2179 Validation Accuracy: 0.540000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.3058 Validation Accuracy: 0.545200\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     1.1119 Validation Accuracy: 0.544800\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.9589 Validation Accuracy: 0.547800\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.2464 Validation Accuracy: 0.543600\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.2109 Validation Accuracy: 0.548000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.2922 Validation Accuracy: 0.551000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     1.1525 Validation Accuracy: 0.543800\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.9419 Validation Accuracy: 0.548000\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.2274 Validation Accuracy: 0.542200\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.2370 Validation Accuracy: 0.545600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.2496 Validation Accuracy: 0.551600\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     1.1225 Validation Accuracy: 0.541600\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.9271 Validation Accuracy: 0.550800\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.2539 Validation Accuracy: 0.556200\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.2007 Validation Accuracy: 0.553200\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.2666 Validation Accuracy: 0.547400\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     1.1286 Validation Accuracy: 0.545200\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.9579 Validation Accuracy: 0.549200\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.2302 Validation Accuracy: 0.553800\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.1994 Validation Accuracy: 0.548600\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.2640 Validation Accuracy: 0.548800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     1.1324 Validation Accuracy: 0.546400\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.9468 Validation Accuracy: 0.549600\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.2444 Validation Accuracy: 0.548400\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.2022 Validation Accuracy: 0.541000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.2849 Validation Accuracy: 0.545800\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     1.1278 Validation Accuracy: 0.542400\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.9635 Validation Accuracy: 0.552400\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.2497 Validation Accuracy: 0.547800\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.1655 Validation Accuracy: 0.544600\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.2617 Validation Accuracy: 0.543400\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     1.1434 Validation Accuracy: 0.546000\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.9185 Validation Accuracy: 0.550000\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.2308 Validation Accuracy: 0.546000\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.1959 Validation Accuracy: 0.539400\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.2640 Validation Accuracy: 0.551000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     1.1112 Validation Accuracy: 0.545600\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.9408 Validation Accuracy: 0.543000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.2047 Validation Accuracy: 0.545000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.2015 Validation Accuracy: 0.546600\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.2818 Validation Accuracy: 0.538000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     1.1488 Validation Accuracy: 0.538800\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.9365 Validation Accuracy: 0.550400\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.2320 Validation Accuracy: 0.540600\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.1838 Validation Accuracy: 0.542000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.2300 Validation Accuracy: 0.553200\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     1.1490 Validation Accuracy: 0.535800\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.9075 Validation Accuracy: 0.548800\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.1427 Validation Accuracy: 0.555000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.1665 Validation Accuracy: 0.542800\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.2249 Validation Accuracy: 0.549000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     1.1159 Validation Accuracy: 0.548600\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.9175 Validation Accuracy: 0.547400\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.1607 Validation Accuracy: 0.548200\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.1810 Validation Accuracy: 0.540600\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.2059 Validation Accuracy: 0.552800\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     1.0929 Validation Accuracy: 0.545600\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.9428 Validation Accuracy: 0.547400\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.1867 Validation Accuracy: 0.547200\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.1804 Validation Accuracy: 0.541400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.1995 Validation Accuracy: 0.551200\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     1.1124 Validation Accuracy: 0.544200\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.9476 Validation Accuracy: 0.548400\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.1927 Validation Accuracy: 0.543400\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.1431 Validation Accuracy: 0.541400\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.2084 Validation Accuracy: 0.553000\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     1.1076 Validation Accuracy: 0.542400\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.9558 Validation Accuracy: 0.545800\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.2093 Validation Accuracy: 0.546200\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.1539 Validation Accuracy: 0.547000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.1729 Validation Accuracy: 0.553200\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     1.0853 Validation Accuracy: 0.548400\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.9328 Validation Accuracy: 0.548200\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.1978 Validation Accuracy: 0.545200\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.1544 Validation Accuracy: 0.541600\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.2044 Validation Accuracy: 0.547400\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     1.0869 Validation Accuracy: 0.548400\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.9159 Validation Accuracy: 0.552000\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.2038 Validation Accuracy: 0.547600\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.1364 Validation Accuracy: 0.553400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.2048 Validation Accuracy: 0.551400\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     1.0784 Validation Accuracy: 0.547400\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.9045 Validation Accuracy: 0.555000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     1.1775 Validation Accuracy: 0.545400\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.1496 Validation Accuracy: 0.542200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.2097 Validation Accuracy: 0.550400\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     1.0800 Validation Accuracy: 0.545000\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.9090 Validation Accuracy: 0.547800\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.1875 Validation Accuracy: 0.542800\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.1442 Validation Accuracy: 0.544600\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.2045 Validation Accuracy: 0.550400\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     1.0730 Validation Accuracy: 0.549600\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.9028 Validation Accuracy: 0.553600\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.1712 Validation Accuracy: 0.547400\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.1353 Validation Accuracy: 0.553000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.2120 Validation Accuracy: 0.549000\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     1.0532 Validation Accuracy: 0.549600\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.9240 Validation Accuracy: 0.552600\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.1876 Validation Accuracy: 0.544200\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.1104 Validation Accuracy: 0.548400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.1492 Validation Accuracy: 0.549400\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     1.0761 Validation Accuracy: 0.540200\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.9556 Validation Accuracy: 0.551400\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     1.1526 Validation Accuracy: 0.549200\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.1069 Validation Accuracy: 0.550400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.1459 Validation Accuracy: 0.554000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     1.0709 Validation Accuracy: 0.544600\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.9130 Validation Accuracy: 0.554200\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     1.1855 Validation Accuracy: 0.546800\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.1168 Validation Accuracy: 0.550400\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.1727 Validation Accuracy: 0.551800\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     1.0463 Validation Accuracy: 0.547400\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.9203 Validation Accuracy: 0.553200\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     1.1661 Validation Accuracy: 0.551600\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.0805 Validation Accuracy: 0.553200\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.1584 Validation Accuracy: 0.555000\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     1.0430 Validation Accuracy: 0.544800\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.9253 Validation Accuracy: 0.550800\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     1.1727 Validation Accuracy: 0.551200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.0809 Validation Accuracy: 0.551400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.1521 Validation Accuracy: 0.553400\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     1.0662 Validation Accuracy: 0.544800\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.9187 Validation Accuracy: 0.554600\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     1.1676 Validation Accuracy: 0.550800\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     1.1086 Validation Accuracy: 0.552200\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.1254 Validation Accuracy: 0.553000\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     1.0216 Validation Accuracy: 0.551000\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.8993 Validation Accuracy: 0.552400\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     1.1695 Validation Accuracy: 0.545200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.0850 Validation Accuracy: 0.550400\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.1254 Validation Accuracy: 0.552200\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     1.0287 Validation Accuracy: 0.551000\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.9272 Validation Accuracy: 0.552600\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     1.1729 Validation Accuracy: 0.548200\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     1.1013 Validation Accuracy: 0.551800\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.1354 Validation Accuracy: 0.554400\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     1.0545 Validation Accuracy: 0.549600\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.8892 Validation Accuracy: 0.555000\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     1.1382 Validation Accuracy: 0.550600\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     1.0870 Validation Accuracy: 0.550400\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.1455 Validation Accuracy: 0.556200\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     1.0337 Validation Accuracy: 0.549400\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.9215 Validation Accuracy: 0.552000\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     1.1544 Validation Accuracy: 0.544000\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     1.0832 Validation Accuracy: 0.550200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.1473 Validation Accuracy: 0.552600\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     1.0516 Validation Accuracy: 0.552800\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.9006 Validation Accuracy: 0.555000\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     1.1344 Validation Accuracy: 0.547600\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     1.1522 Validation Accuracy: 0.547800\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.1351 Validation Accuracy: 0.549800\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     1.0165 Validation Accuracy: 0.548600\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.8847 Validation Accuracy: 0.551600\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     1.1169 Validation Accuracy: 0.552400\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     1.0970 Validation Accuracy: 0.552000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.1537 Validation Accuracy: 0.554800\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     1.0123 Validation Accuracy: 0.550400\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     0.8731 Validation Accuracy: 0.552000\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     1.1054 Validation Accuracy: 0.549400\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     1.0889 Validation Accuracy: 0.551000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.1507 Validation Accuracy: 0.550000\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     1.0058 Validation Accuracy: 0.550800\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     0.9013 Validation Accuracy: 0.555200\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     1.1295 Validation Accuracy: 0.554000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     1.0792 Validation Accuracy: 0.549400\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.1086 Validation Accuracy: 0.557400\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     1.0197 Validation Accuracy: 0.547800\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     0.8693 Validation Accuracy: 0.554000\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     1.1254 Validation Accuracy: 0.546000\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     1.1263 Validation Accuracy: 0.544400\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.0883 Validation Accuracy: 0.552200\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     1.0471 Validation Accuracy: 0.549200\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     0.9169 Validation Accuracy: 0.557400\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     1.1586 Validation Accuracy: 0.547000\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     1.0730 Validation Accuracy: 0.550000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.1238 Validation Accuracy: 0.556600\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     1.0395 Validation Accuracy: 0.540600\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     0.8992 Validation Accuracy: 0.554400\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     1.1798 Validation Accuracy: 0.538000\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     1.0552 Validation Accuracy: 0.551600\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.1349 Validation Accuracy: 0.548000\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     1.0241 Validation Accuracy: 0.544400\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     0.9049 Validation Accuracy: 0.556600\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     1.1121 Validation Accuracy: 0.551000\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     1.0886 Validation Accuracy: 0.549600\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.1336 Validation Accuracy: 0.547000\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     0.9888 Validation Accuracy: 0.552000\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     0.9049 Validation Accuracy: 0.551800\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     1.1142 Validation Accuracy: 0.555400\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     1.0654 Validation Accuracy: 0.551000\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.1459 Validation Accuracy: 0.552600\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     1.0004 Validation Accuracy: 0.550000\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     0.9166 Validation Accuracy: 0.554800\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     1.0949 Validation Accuracy: 0.552200\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     1.0939 Validation Accuracy: 0.558200\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.1368 Validation Accuracy: 0.553200\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     0.9846 Validation Accuracy: 0.546000\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     0.8926 Validation Accuracy: 0.553400\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     1.0715 Validation Accuracy: 0.552000\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     1.0687 Validation Accuracy: 0.555600\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.1156 Validation Accuracy: 0.547400\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     1.0093 Validation Accuracy: 0.549600\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     0.9133 Validation Accuracy: 0.552200\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     1.1088 Validation Accuracy: 0.546000\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     1.0845 Validation Accuracy: 0.553600\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.0867 Validation Accuracy: 0.548600\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     1.0111 Validation Accuracy: 0.548600\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     0.8982 Validation Accuracy: 0.550600\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     1.1297 Validation Accuracy: 0.547400\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     1.0858 Validation Accuracy: 0.551000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.0997 Validation Accuracy: 0.551600\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     1.0159 Validation Accuracy: 0.554000\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     0.9101 Validation Accuracy: 0.555600\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     1.1020 Validation Accuracy: 0.552200\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     1.0998 Validation Accuracy: 0.553400\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.1249 Validation Accuracy: 0.551200\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     1.0015 Validation Accuracy: 0.556800\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     0.8952 Validation Accuracy: 0.552000\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     1.0924 Validation Accuracy: 0.555600\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     1.0756 Validation Accuracy: 0.553800\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.0977 Validation Accuracy: 0.551600\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     1.0021 Validation Accuracy: 0.555000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     0.8776 Validation Accuracy: 0.554400\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     1.0709 Validation Accuracy: 0.552600\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     1.0426 Validation Accuracy: 0.555200\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.0569 Validation Accuracy: 0.551000\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     1.0093 Validation Accuracy: 0.545200\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     0.8969 Validation Accuracy: 0.551400\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     1.0888 Validation Accuracy: 0.558200\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     1.0565 Validation Accuracy: 0.558800\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.0599 Validation Accuracy: 0.554400\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     0.9847 Validation Accuracy: 0.549600\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     0.9221 Validation Accuracy: 0.558000\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     1.0864 Validation Accuracy: 0.560600\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     1.0730 Validation Accuracy: 0.555600\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.0724 Validation Accuracy: 0.554800\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     0.9642 Validation Accuracy: 0.547000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     0.9103 Validation Accuracy: 0.552200\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     1.0787 Validation Accuracy: 0.553200\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     1.0979 Validation Accuracy: 0.551000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.0839 Validation Accuracy: 0.549600\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     0.9788 Validation Accuracy: 0.552800\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.8951 Validation Accuracy: 0.559800\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     1.1129 Validation Accuracy: 0.551200\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     1.0778 Validation Accuracy: 0.550000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.0740 Validation Accuracy: 0.558600\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     0.9628 Validation Accuracy: 0.550800\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     0.8928 Validation Accuracy: 0.557400\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     1.0883 Validation Accuracy: 0.555400\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     1.0733 Validation Accuracy: 0.552000\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.0548 Validation Accuracy: 0.551200\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     0.9942 Validation Accuracy: 0.555800\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     0.9086 Validation Accuracy: 0.560600\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     1.0626 Validation Accuracy: 0.556400\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     1.0410 Validation Accuracy: 0.558600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.0370 Validation Accuracy: 0.552400\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     1.0021 Validation Accuracy: 0.549800\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     0.9092 Validation Accuracy: 0.561600\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     1.0673 Validation Accuracy: 0.554800\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     1.0508 Validation Accuracy: 0.554800\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.0764 Validation Accuracy: 0.553800\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     1.0150 Validation Accuracy: 0.547400\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.9025 Validation Accuracy: 0.551400\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     1.0434 Validation Accuracy: 0.559600\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     1.0794 Validation Accuracy: 0.553000\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.0316 Validation Accuracy: 0.555000\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     0.9649 Validation Accuracy: 0.555600\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     0.9109 Validation Accuracy: 0.556800\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     1.0705 Validation Accuracy: 0.559600\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     1.0132 Validation Accuracy: 0.557600\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.0124 Validation Accuracy: 0.550400\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     1.0071 Validation Accuracy: 0.554200\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     0.9144 Validation Accuracy: 0.560600\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     1.0474 Validation Accuracy: 0.553200\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     1.0424 Validation Accuracy: 0.558400\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.0495 Validation Accuracy: 0.554000\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.9860 Validation Accuracy: 0.554800\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     0.9001 Validation Accuracy: 0.557400\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     1.0426 Validation Accuracy: 0.557400\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     1.0647 Validation Accuracy: 0.555200\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.0289 Validation Accuracy: 0.557400\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     0.9781 Validation Accuracy: 0.552400\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     0.9197 Validation Accuracy: 0.553000\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     1.0925 Validation Accuracy: 0.552000\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     1.0311 Validation Accuracy: 0.554000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.0319 Validation Accuracy: 0.554400\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.9738 Validation Accuracy: 0.552600\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     0.8925 Validation Accuracy: 0.556800\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     1.0537 Validation Accuracy: 0.555600\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     1.0511 Validation Accuracy: 0.554600\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.0514 Validation Accuracy: 0.555000\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     0.9523 Validation Accuracy: 0.552600\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.8939 Validation Accuracy: 0.553400\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     1.0305 Validation Accuracy: 0.556200\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     1.0606 Validation Accuracy: 0.551200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.0336 Validation Accuracy: 0.555800\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.9656 Validation Accuracy: 0.553800\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.9078 Validation Accuracy: 0.557600\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     1.0787 Validation Accuracy: 0.551000\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     1.0536 Validation Accuracy: 0.556000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.0483 Validation Accuracy: 0.559800\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.9840 Validation Accuracy: 0.553400\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.9108 Validation Accuracy: 0.562400\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     1.0324 Validation Accuracy: 0.553400\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     1.0122 Validation Accuracy: 0.556400\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.0811 Validation Accuracy: 0.553600\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:     0.9708 Validation Accuracy: 0.551200\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:     0.8743 Validation Accuracy: 0.561400\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:     1.0209 Validation Accuracy: 0.560000\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:     1.0414 Validation Accuracy: 0.548800\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     1.0566 Validation Accuracy: 0.560400\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:     0.9879 Validation Accuracy: 0.556800\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:     0.9106 Validation Accuracy: 0.563400\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:     1.0564 Validation Accuracy: 0.557000\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:     1.0603 Validation Accuracy: 0.550000\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     1.0274 Validation Accuracy: 0.552800\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:     0.9673 Validation Accuracy: 0.558200\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:     0.9142 Validation Accuracy: 0.557000\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:     1.0247 Validation Accuracy: 0.556000\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:     1.0339 Validation Accuracy: 0.560400\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     1.0584 Validation Accuracy: 0.557400\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:     0.9734 Validation Accuracy: 0.555400\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:     0.8915 Validation Accuracy: 0.557400\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:     1.0326 Validation Accuracy: 0.559200\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:     1.0301 Validation Accuracy: 0.555600\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.0191 Validation Accuracy: 0.551400\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:     0.9527 Validation Accuracy: 0.556800\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:     0.8944 Validation Accuracy: 0.562000\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:     1.0288 Validation Accuracy: 0.556800\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:     1.0681 Validation Accuracy: 0.557200\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     1.0033 Validation Accuracy: 0.553800\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:     0.9754 Validation Accuracy: 0.551200\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:     0.9072 Validation Accuracy: 0.564800\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:     1.0307 Validation Accuracy: 0.555800\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:     1.0475 Validation Accuracy: 0.554600\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     1.0500 Validation Accuracy: 0.551800\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:     0.9527 Validation Accuracy: 0.556800\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:     0.9203 Validation Accuracy: 0.560000\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:     1.0335 Validation Accuracy: 0.556800\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:     1.0492 Validation Accuracy: 0.559400\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     1.0321 Validation Accuracy: 0.558400\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:     0.9554 Validation Accuracy: 0.557400\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:     0.9161 Validation Accuracy: 0.559000\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:     1.0194 Validation Accuracy: 0.561200\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss:     1.0063 Validation Accuracy: 0.560800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     1.0331 Validation Accuracy: 0.558000\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:     0.9432 Validation Accuracy: 0.553200\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:     0.9144 Validation Accuracy: 0.558400\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:     1.0085 Validation Accuracy: 0.562000\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:     1.0242 Validation Accuracy: 0.553600\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     0.9917 Validation Accuracy: 0.556400\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:     0.9331 Validation Accuracy: 0.556800\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:     0.9082 Validation Accuracy: 0.561000\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:     0.9954 Validation Accuracy: 0.560600\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:     1.0377 Validation Accuracy: 0.563400\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     0.9937 Validation Accuracy: 0.557200\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:     0.9483 Validation Accuracy: 0.558600\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:     0.9040 Validation Accuracy: 0.554000\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:     1.0243 Validation Accuracy: 0.560800\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:     1.0428 Validation Accuracy: 0.558200\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     0.9959 Validation Accuracy: 0.557400\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:     0.9280 Validation Accuracy: 0.556600\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:     0.8705 Validation Accuracy: 0.559600\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:     0.9830 Validation Accuracy: 0.557600\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:     1.0229 Validation Accuracy: 0.562000\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     1.0095 Validation Accuracy: 0.556000\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:     0.9205 Validation Accuracy: 0.556800\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:     0.8704 Validation Accuracy: 0.560200\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:     1.0090 Validation Accuracy: 0.558200\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:     1.0386 Validation Accuracy: 0.558800\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     0.9935 Validation Accuracy: 0.556200\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:     0.9388 Validation Accuracy: 0.556200\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:     0.8814 Validation Accuracy: 0.558800\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:     1.0005 Validation Accuracy: 0.559600\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:     1.0258 Validation Accuracy: 0.555200\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     1.0002 Validation Accuracy: 0.559800\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:     0.9201 Validation Accuracy: 0.559000\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:     0.8931 Validation Accuracy: 0.554200\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:     1.0107 Validation Accuracy: 0.555200\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:     1.0201 Validation Accuracy: 0.560200\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     0.9936 Validation Accuracy: 0.555200\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:     0.9235 Validation Accuracy: 0.556200\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:     0.8966 Validation Accuracy: 0.566200\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:     0.9974 Validation Accuracy: 0.557600\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:     1.0280 Validation Accuracy: 0.553400\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     1.0139 Validation Accuracy: 0.559600\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:     0.9435 Validation Accuracy: 0.553800\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:     0.9084 Validation Accuracy: 0.552800\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:     1.0047 Validation Accuracy: 0.560800\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:     1.0313 Validation Accuracy: 0.552800\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     0.9809 Validation Accuracy: 0.558000\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:     0.9203 Validation Accuracy: 0.557400\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:     0.8817 Validation Accuracy: 0.559000\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:     1.0012 Validation Accuracy: 0.558400\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:     1.0322 Validation Accuracy: 0.546000\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     1.0083 Validation Accuracy: 0.556000\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:     0.9283 Validation Accuracy: 0.557600\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:     0.8859 Validation Accuracy: 0.561400\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:     0.9904 Validation Accuracy: 0.561000\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:     1.0127 Validation Accuracy: 0.555400\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     0.9863 Validation Accuracy: 0.559000\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:     0.9451 Validation Accuracy: 0.558800\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:     0.8785 Validation Accuracy: 0.558600\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:     1.0069 Validation Accuracy: 0.558000\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:     1.0047 Validation Accuracy: 0.557000\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     0.9847 Validation Accuracy: 0.557200\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:     0.9388 Validation Accuracy: 0.551000\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:     0.8819 Validation Accuracy: 0.556000\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:     0.9868 Validation Accuracy: 0.563200\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:     1.0228 Validation Accuracy: 0.562200\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     1.0189 Validation Accuracy: 0.561400\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:     0.9376 Validation Accuracy: 0.562200\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:     0.8822 Validation Accuracy: 0.553800\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:     1.0137 Validation Accuracy: 0.560000\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:     1.0174 Validation Accuracy: 0.556000\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     0.9954 Validation Accuracy: 0.558600\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:     0.9445 Validation Accuracy: 0.559200\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:     0.8938 Validation Accuracy: 0.559400\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:     0.9929 Validation Accuracy: 0.558800\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:     1.0034 Validation Accuracy: 0.560800\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     0.9835 Validation Accuracy: 0.557000\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:     0.9345 Validation Accuracy: 0.556000\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:     0.8710 Validation Accuracy: 0.557600\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:     1.0084 Validation Accuracy: 0.559000\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:     1.0064 Validation Accuracy: 0.550600\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     0.9960 Validation Accuracy: 0.555200\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:     0.9316 Validation Accuracy: 0.559600\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:     0.8703 Validation Accuracy: 0.560400\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:     0.9932 Validation Accuracy: 0.563000\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:     1.0004 Validation Accuracy: 0.552800\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     0.9983 Validation Accuracy: 0.558200\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:     0.9230 Validation Accuracy: 0.566000\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:     0.9115 Validation Accuracy: 0.555800\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:     0.9897 Validation Accuracy: 0.561600\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:     1.0006 Validation Accuracy: 0.558400\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     0.9928 Validation Accuracy: 0.560800\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:     0.9134 Validation Accuracy: 0.557000\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:     0.8869 Validation Accuracy: 0.556200\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:     0.9728 Validation Accuracy: 0.560600\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:     1.0118 Validation Accuracy: 0.558000\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     0.9837 Validation Accuracy: 0.554000\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:     0.9512 Validation Accuracy: 0.558000\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:     0.8833 Validation Accuracy: 0.560200\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:     0.9750 Validation Accuracy: 0.562800\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:     1.0083 Validation Accuracy: 0.555400\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     0.9773 Validation Accuracy: 0.562000\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss:     0.9502 Validation Accuracy: 0.555800\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:     0.8862 Validation Accuracy: 0.559600\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:     0.9756 Validation Accuracy: 0.558800\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:     1.0088 Validation Accuracy: 0.559200\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     0.9911 Validation Accuracy: 0.559200\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss:     0.9374 Validation Accuracy: 0.558400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, CIFAR-10 Batch 3:  Loss:     0.8400 Validation Accuracy: 0.562800\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:     0.9598 Validation Accuracy: 0.560600\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:     1.0121 Validation Accuracy: 0.557400\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     0.9784 Validation Accuracy: 0.553600\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:     0.9602 Validation Accuracy: 0.561800\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:     0.8712 Validation Accuracy: 0.559800\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:     0.9777 Validation Accuracy: 0.563200\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:     0.9966 Validation Accuracy: 0.558000\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     0.9976 Validation Accuracy: 0.554600\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:     0.9296 Validation Accuracy: 0.562000\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:     0.8663 Validation Accuracy: 0.558600\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:     0.9543 Validation Accuracy: 0.561400\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:     1.0143 Validation Accuracy: 0.562200\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     0.9688 Validation Accuracy: 0.555400\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:     0.9499 Validation Accuracy: 0.559000\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:     0.8698 Validation Accuracy: 0.559800\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:     0.9788 Validation Accuracy: 0.558600\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:     1.0146 Validation Accuracy: 0.555200\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     0.9607 Validation Accuracy: 0.560600\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:     0.9514 Validation Accuracy: 0.552600\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:     0.9030 Validation Accuracy: 0.556600\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:     0.9741 Validation Accuracy: 0.566000\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:     1.0130 Validation Accuracy: 0.561200\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     0.9788 Validation Accuracy: 0.559000\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:     0.9113 Validation Accuracy: 0.559800\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:     0.8755 Validation Accuracy: 0.562800\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:     0.9416 Validation Accuracy: 0.563400\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:     1.0313 Validation Accuracy: 0.563000\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     0.9737 Validation Accuracy: 0.560000\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:     0.9338 Validation Accuracy: 0.562000\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:     0.8567 Validation Accuracy: 0.566000\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:     0.9343 Validation Accuracy: 0.561200\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:     1.0197 Validation Accuracy: 0.554000\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     0.9799 Validation Accuracy: 0.560400\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:     0.9702 Validation Accuracy: 0.557600\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:     0.8957 Validation Accuracy: 0.561200\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:     0.9619 Validation Accuracy: 0.563800\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:     0.9948 Validation Accuracy: 0.550800\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     0.9855 Validation Accuracy: 0.558600\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:     0.9206 Validation Accuracy: 0.562600\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:     0.8743 Validation Accuracy: 0.560200\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:     0.9605 Validation Accuracy: 0.563200\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:     1.0048 Validation Accuracy: 0.562000\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     0.9559 Validation Accuracy: 0.559400\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:     0.9368 Validation Accuracy: 0.560600\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:     0.8788 Validation Accuracy: 0.552400\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:     0.9392 Validation Accuracy: 0.562600\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:     1.0038 Validation Accuracy: 0.552400\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     0.9773 Validation Accuracy: 0.560800\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:     0.9327 Validation Accuracy: 0.561200\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:     0.8682 Validation Accuracy: 0.557000\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:     0.9440 Validation Accuracy: 0.565800\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:     1.0028 Validation Accuracy: 0.556400\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     0.9616 Validation Accuracy: 0.561400\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:     0.9153 Validation Accuracy: 0.558000\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:     0.8453 Validation Accuracy: 0.561400\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:     0.9418 Validation Accuracy: 0.561600\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:     1.0099 Validation Accuracy: 0.561000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     0.9743 Validation Accuracy: 0.559400\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:     0.9094 Validation Accuracy: 0.560800\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:     0.8653 Validation Accuracy: 0.560400\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:     0.9495 Validation Accuracy: 0.565400\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:     1.0155 Validation Accuracy: 0.562200\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     0.9598 Validation Accuracy: 0.562600\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:     0.9365 Validation Accuracy: 0.555200\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:     0.8183 Validation Accuracy: 0.567000\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:     0.9222 Validation Accuracy: 0.564600\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:     1.0191 Validation Accuracy: 0.560800\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     0.9660 Validation Accuracy: 0.559000\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:     0.9100 Validation Accuracy: 0.558000\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:     0.8711 Validation Accuracy: 0.560200\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:     0.9452 Validation Accuracy: 0.560400\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:     1.0142 Validation Accuracy: 0.561600\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     0.9492 Validation Accuracy: 0.559400\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:     0.9486 Validation Accuracy: 0.560400\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:     0.8641 Validation Accuracy: 0.559800\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:     0.9254 Validation Accuracy: 0.566000\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:     1.0077 Validation Accuracy: 0.560600\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     0.9752 Validation Accuracy: 0.558000\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:     0.9159 Validation Accuracy: 0.566600\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:     0.8653 Validation Accuracy: 0.562400\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:     0.9142 Validation Accuracy: 0.562600\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:     0.9947 Validation Accuracy: 0.558600\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     0.9621 Validation Accuracy: 0.562200\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:     0.8937 Validation Accuracy: 0.565800\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:     0.8722 Validation Accuracy: 0.565000\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:     0.9079 Validation Accuracy: 0.565000\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:     1.0036 Validation Accuracy: 0.565800\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     0.9536 Validation Accuracy: 0.556600\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:     0.9220 Validation Accuracy: 0.556800\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:     0.8611 Validation Accuracy: 0.562000\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:     0.9096 Validation Accuracy: 0.563400\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:     1.0022 Validation Accuracy: 0.560400\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     0.9964 Validation Accuracy: 0.557200\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:     0.8960 Validation Accuracy: 0.561600\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:     0.8449 Validation Accuracy: 0.561600\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:     0.9112 Validation Accuracy: 0.564800\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:     1.0117 Validation Accuracy: 0.566400\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     0.9753 Validation Accuracy: 0.562000\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:     0.9065 Validation Accuracy: 0.559400\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:     0.8707 Validation Accuracy: 0.562400\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:     0.9138 Validation Accuracy: 0.566600\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:     0.9988 Validation Accuracy: 0.565800\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     0.9600 Validation Accuracy: 0.563800\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:     0.8970 Validation Accuracy: 0.555600\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:     0.8572 Validation Accuracy: 0.559800\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss:     0.8979 Validation Accuracy: 0.567200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151, CIFAR-10 Batch 5:  Loss:     0.9843 Validation Accuracy: 0.557000\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     0.9596 Validation Accuracy: 0.559000\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:     0.8886 Validation Accuracy: 0.561200\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:     0.8422 Validation Accuracy: 0.563600\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:     0.9090 Validation Accuracy: 0.566200\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:     1.0056 Validation Accuracy: 0.560200\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     0.9680 Validation Accuracy: 0.558600\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:     0.9083 Validation Accuracy: 0.565200\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:     0.8475 Validation Accuracy: 0.560000\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:     0.9155 Validation Accuracy: 0.561800\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:     0.9991 Validation Accuracy: 0.558000\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     0.9432 Validation Accuracy: 0.558800\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:     0.8919 Validation Accuracy: 0.562000\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:     0.8370 Validation Accuracy: 0.556800\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:     0.9376 Validation Accuracy: 0.560000\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:     0.9609 Validation Accuracy: 0.565200\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     0.9483 Validation Accuracy: 0.560800\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:     0.8958 Validation Accuracy: 0.564600\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:     0.8292 Validation Accuracy: 0.564000\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:     0.9167 Validation Accuracy: 0.571000\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:     0.9982 Validation Accuracy: 0.559000\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     0.9686 Validation Accuracy: 0.561000\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:     0.9056 Validation Accuracy: 0.563400\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:     0.8343 Validation Accuracy: 0.564200\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:     0.9204 Validation Accuracy: 0.563800\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:     0.9987 Validation Accuracy: 0.564800\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     0.9637 Validation Accuracy: 0.562800\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:     0.8949 Validation Accuracy: 0.559000\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:     0.8053 Validation Accuracy: 0.559200\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:     0.9063 Validation Accuracy: 0.565000\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:     0.9717 Validation Accuracy: 0.568000\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     0.9778 Validation Accuracy: 0.563000\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:     0.9049 Validation Accuracy: 0.559200\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:     0.8486 Validation Accuracy: 0.559600\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:     0.9203 Validation Accuracy: 0.557600\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:     0.9940 Validation Accuracy: 0.562000\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     0.9777 Validation Accuracy: 0.558800\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:     0.8879 Validation Accuracy: 0.562200\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:     0.8515 Validation Accuracy: 0.568200\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:     0.9042 Validation Accuracy: 0.569000\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:     0.9786 Validation Accuracy: 0.562400\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     0.9666 Validation Accuracy: 0.566600\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:     0.8728 Validation Accuracy: 0.562600\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:     0.8360 Validation Accuracy: 0.566200\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:     0.9111 Validation Accuracy: 0.566000\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:     0.9848 Validation Accuracy: 0.566600\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     0.9746 Validation Accuracy: 0.560800\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:     0.8701 Validation Accuracy: 0.566000\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:     0.8388 Validation Accuracy: 0.555400\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:     0.9092 Validation Accuracy: 0.563400\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:     0.9940 Validation Accuracy: 0.563200\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     0.9618 Validation Accuracy: 0.566600\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:     0.8982 Validation Accuracy: 0.562400\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:     0.8651 Validation Accuracy: 0.557400\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:     0.8890 Validation Accuracy: 0.562800\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:     0.9706 Validation Accuracy: 0.558800\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     0.9516 Validation Accuracy: 0.569000\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:     0.8974 Validation Accuracy: 0.565400\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:     0.8201 Validation Accuracy: 0.560600\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:     0.9020 Validation Accuracy: 0.563800\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:     0.9844 Validation Accuracy: 0.557600\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     0.9620 Validation Accuracy: 0.562600\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:     0.8819 Validation Accuracy: 0.560000\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:     0.8327 Validation Accuracy: 0.567000\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:     0.8968 Validation Accuracy: 0.565200\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:     0.9863 Validation Accuracy: 0.561200\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     0.9784 Validation Accuracy: 0.556400\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:     0.8611 Validation Accuracy: 0.561000\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:     0.8311 Validation Accuracy: 0.560800\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:     0.8862 Validation Accuracy: 0.569000\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:     0.9934 Validation Accuracy: 0.555800\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     0.9859 Validation Accuracy: 0.560200\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:     0.8694 Validation Accuracy: 0.569200\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:     0.8397 Validation Accuracy: 0.563400\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:     0.8940 Validation Accuracy: 0.572600\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:     0.9989 Validation Accuracy: 0.561800\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     0.9455 Validation Accuracy: 0.564400\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:     0.8836 Validation Accuracy: 0.557000\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:     0.8490 Validation Accuracy: 0.560400\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:     0.9015 Validation Accuracy: 0.568400\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:     0.9695 Validation Accuracy: 0.565400\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     0.9432 Validation Accuracy: 0.564800\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:     0.8808 Validation Accuracy: 0.564200\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:     0.8434 Validation Accuracy: 0.564000\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:     0.9041 Validation Accuracy: 0.565800\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:     1.0019 Validation Accuracy: 0.557000\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     0.9740 Validation Accuracy: 0.561400\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:     0.8486 Validation Accuracy: 0.567000\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:     0.8243 Validation Accuracy: 0.566200\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:     0.9004 Validation Accuracy: 0.569600\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:     0.9618 Validation Accuracy: 0.562800\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     0.9478 Validation Accuracy: 0.559600\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:     0.8761 Validation Accuracy: 0.562800\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:     0.8129 Validation Accuracy: 0.566400\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:     0.9074 Validation Accuracy: 0.563200\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:     0.9713 Validation Accuracy: 0.562200\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     0.9708 Validation Accuracy: 0.563800\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:     0.8704 Validation Accuracy: 0.565000\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:     0.8164 Validation Accuracy: 0.565200\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss:     0.9113 Validation Accuracy: 0.567200\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:     0.9697 Validation Accuracy: 0.560400\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     0.9681 Validation Accuracy: 0.564000\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:     0.8909 Validation Accuracy: 0.562200\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:     0.8006 Validation Accuracy: 0.565800\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:     0.9120 Validation Accuracy: 0.562800\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:     0.9729 Validation Accuracy: 0.568600\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     0.9723 Validation Accuracy: 0.560800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173, CIFAR-10 Batch 2:  Loss:     0.9081 Validation Accuracy: 0.561000\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:     0.8045 Validation Accuracy: 0.565800\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:     0.8690 Validation Accuracy: 0.567200\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:     0.9613 Validation Accuracy: 0.562200\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     0.9622 Validation Accuracy: 0.567000\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:     0.8798 Validation Accuracy: 0.569800\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:     0.8259 Validation Accuracy: 0.567200\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:     0.8974 Validation Accuracy: 0.563000\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:     0.9465 Validation Accuracy: 0.567800\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     0.9519 Validation Accuracy: 0.564600\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:     0.8541 Validation Accuracy: 0.560800\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:     0.8355 Validation Accuracy: 0.569800\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:     0.8989 Validation Accuracy: 0.569400\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:     0.9676 Validation Accuracy: 0.562200\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     0.9565 Validation Accuracy: 0.565400\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:     0.8808 Validation Accuracy: 0.566800\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:     0.8239 Validation Accuracy: 0.568000\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:     0.8947 Validation Accuracy: 0.565800\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:     0.9735 Validation Accuracy: 0.564000\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     0.9502 Validation Accuracy: 0.564400\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:     0.8761 Validation Accuracy: 0.568400\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:     0.8310 Validation Accuracy: 0.565000\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:     0.8813 Validation Accuracy: 0.570200\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:     0.9577 Validation Accuracy: 0.569800\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     0.9445 Validation Accuracy: 0.568000\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:     0.8892 Validation Accuracy: 0.563000\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:     0.8169 Validation Accuracy: 0.566000\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:     0.8764 Validation Accuracy: 0.570400\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:     0.9587 Validation Accuracy: 0.567000\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     0.9422 Validation Accuracy: 0.566000\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:     0.8686 Validation Accuracy: 0.567800\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:     0.8309 Validation Accuracy: 0.566400\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:     0.9223 Validation Accuracy: 0.564800\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:     0.9467 Validation Accuracy: 0.565600\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     0.9752 Validation Accuracy: 0.560600\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:     0.8837 Validation Accuracy: 0.565200\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:     0.8196 Validation Accuracy: 0.562800\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:     0.8749 Validation Accuracy: 0.567200\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:     0.9879 Validation Accuracy: 0.564200\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     0.9377 Validation Accuracy: 0.564600\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:     0.8513 Validation Accuracy: 0.565200\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:     0.8237 Validation Accuracy: 0.564600\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:     0.8999 Validation Accuracy: 0.563400\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:     0.9482 Validation Accuracy: 0.558600\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     0.9267 Validation Accuracy: 0.563800\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:     0.8627 Validation Accuracy: 0.558200\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:     0.8219 Validation Accuracy: 0.565000\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:     0.8791 Validation Accuracy: 0.567000\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:     0.9545 Validation Accuracy: 0.561200\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     0.9394 Validation Accuracy: 0.560400\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:     0.8626 Validation Accuracy: 0.560800\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:     0.8378 Validation Accuracy: 0.561200\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:     0.8746 Validation Accuracy: 0.562800\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:     0.9557 Validation Accuracy: 0.556800\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     0.9401 Validation Accuracy: 0.565000\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:     0.8747 Validation Accuracy: 0.565400\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:     0.8206 Validation Accuracy: 0.561600\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:     0.8623 Validation Accuracy: 0.566600\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:     0.9059 Validation Accuracy: 0.562600\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     0.9303 Validation Accuracy: 0.564200\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:     0.9096 Validation Accuracy: 0.564400\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:     0.8071 Validation Accuracy: 0.567800\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:     0.8716 Validation Accuracy: 0.566000\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:     0.9482 Validation Accuracy: 0.557800\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     0.9238 Validation Accuracy: 0.565400\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:     0.8859 Validation Accuracy: 0.566400\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:     0.8027 Validation Accuracy: 0.563200\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:     0.8920 Validation Accuracy: 0.569400\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:     0.9576 Validation Accuracy: 0.568400\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     0.9205 Validation Accuracy: 0.569800\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:     0.8679 Validation Accuracy: 0.560600\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:     0.8054 Validation Accuracy: 0.567000\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:     0.8806 Validation Accuracy: 0.564200\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:     0.9651 Validation Accuracy: 0.557800\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     0.9451 Validation Accuracy: 0.565200\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:     0.8583 Validation Accuracy: 0.564200\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:     0.8079 Validation Accuracy: 0.568600\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:     0.8939 Validation Accuracy: 0.567200\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:     0.9511 Validation Accuracy: 0.559600\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     0.9394 Validation Accuracy: 0.564800\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:     0.8416 Validation Accuracy: 0.562800\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:     0.8212 Validation Accuracy: 0.566600\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:     0.8624 Validation Accuracy: 0.566600\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:     0.9492 Validation Accuracy: 0.560600\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     0.9415 Validation Accuracy: 0.571200\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:     0.8571 Validation Accuracy: 0.563400\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:     0.7981 Validation Accuracy: 0.565600\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:     0.8633 Validation Accuracy: 0.567200\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:     0.9439 Validation Accuracy: 0.562600\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     0.9426 Validation Accuracy: 0.568400\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:     0.8539 Validation Accuracy: 0.561600\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:     0.8163 Validation Accuracy: 0.567200\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:     0.8756 Validation Accuracy: 0.569600\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:     0.9336 Validation Accuracy: 0.567200\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     0.9233 Validation Accuracy: 0.567400\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:     0.8476 Validation Accuracy: 0.569000\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:     0.8214 Validation Accuracy: 0.566200\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:     0.8450 Validation Accuracy: 0.570600\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:     0.9457 Validation Accuracy: 0.559800\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     0.9344 Validation Accuracy: 0.564000\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:     0.8514 Validation Accuracy: 0.560600\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:     0.8415 Validation Accuracy: 0.560400\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:     0.8556 Validation Accuracy: 0.567400\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:     0.9283 Validation Accuracy: 0.558000\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     0.9599 Validation Accuracy: 0.561600\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:     0.8559 Validation Accuracy: 0.562400\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss:     0.8421 Validation Accuracy: 0.559400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194, CIFAR-10 Batch 4:  Loss:     0.8575 Validation Accuracy: 0.572400\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:     0.9343 Validation Accuracy: 0.568800\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     0.9355 Validation Accuracy: 0.565000\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:     0.8685 Validation Accuracy: 0.568000\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:     0.8219 Validation Accuracy: 0.566000\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:     0.8681 Validation Accuracy: 0.569800\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:     0.9282 Validation Accuracy: 0.561000\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     0.9255 Validation Accuracy: 0.565000\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:     0.8428 Validation Accuracy: 0.567000\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:     0.8087 Validation Accuracy: 0.560800\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:     0.8542 Validation Accuracy: 0.568200\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:     0.9456 Validation Accuracy: 0.572000\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     0.9303 Validation Accuracy: 0.569600\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:     0.8247 Validation Accuracy: 0.564400\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:     0.8349 Validation Accuracy: 0.570400\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:     0.8849 Validation Accuracy: 0.569200\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:     0.9621 Validation Accuracy: 0.565200\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     0.9252 Validation Accuracy: 0.566200\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:     0.8333 Validation Accuracy: 0.565600\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:     0.8097 Validation Accuracy: 0.570200\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:     0.8878 Validation Accuracy: 0.567200\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:     0.9336 Validation Accuracy: 0.566000\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     0.9104 Validation Accuracy: 0.571800\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:     0.8428 Validation Accuracy: 0.562800\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:     0.7967 Validation Accuracy: 0.568600\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:     0.8813 Validation Accuracy: 0.566000\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:     0.9366 Validation Accuracy: 0.561400\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     0.9210 Validation Accuracy: 0.565400\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:     0.8626 Validation Accuracy: 0.569000\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:     0.7925 Validation Accuracy: 0.567200\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:     0.8755 Validation Accuracy: 0.569600\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:     0.9147 Validation Accuracy: 0.561400\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     0.9433 Validation Accuracy: 0.566000\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss:     0.8430 Validation Accuracy: 0.567200\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss:     0.8216 Validation Accuracy: 0.564600\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss:     0.8694 Validation Accuracy: 0.572200\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss:     0.9231 Validation Accuracy: 0.565600\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     0.9119 Validation Accuracy: 0.570800\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss:     0.8415 Validation Accuracy: 0.564000\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss:     0.7996 Validation Accuracy: 0.571000\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss:     0.8720 Validation Accuracy: 0.573600\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss:     0.9069 Validation Accuracy: 0.561600\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     0.9343 Validation Accuracy: 0.565600\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss:     0.8534 Validation Accuracy: 0.567200\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss:     0.8200 Validation Accuracy: 0.569800\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss:     0.8519 Validation Accuracy: 0.567600\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss:     0.9015 Validation Accuracy: 0.566200\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     0.9339 Validation Accuracy: 0.565000\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss:     0.8739 Validation Accuracy: 0.566400\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss:     0.8173 Validation Accuracy: 0.563000\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss:     0.8900 Validation Accuracy: 0.563200\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss:     0.9278 Validation Accuracy: 0.555600\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     0.9340 Validation Accuracy: 0.567000\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss:     0.8413 Validation Accuracy: 0.568800\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss:     0.8182 Validation Accuracy: 0.569200\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss:     0.8497 Validation Accuracy: 0.568200\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss:     0.9318 Validation Accuracy: 0.566600\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     0.9496 Validation Accuracy: 0.560200\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss:     0.8404 Validation Accuracy: 0.560600\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss:     0.8449 Validation Accuracy: 0.564400\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss:     0.8729 Validation Accuracy: 0.563800\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss:     0.9510 Validation Accuracy: 0.564600\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     0.9183 Validation Accuracy: 0.567000\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss:     0.8512 Validation Accuracy: 0.565200\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss:     0.8273 Validation Accuracy: 0.563600\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss:     0.8483 Validation Accuracy: 0.569800\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss:     0.9501 Validation Accuracy: 0.562800\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     0.9338 Validation Accuracy: 0.566200\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss:     0.8569 Validation Accuracy: 0.565600\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss:     0.8087 Validation Accuracy: 0.570600\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss:     0.8544 Validation Accuracy: 0.571200\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss:     0.9381 Validation Accuracy: 0.566000\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     0.9339 Validation Accuracy: 0.572800\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss:     0.8405 Validation Accuracy: 0.567800\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss:     0.8144 Validation Accuracy: 0.565600\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss:     0.8432 Validation Accuracy: 0.570200\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss:     0.9303 Validation Accuracy: 0.561800\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     0.9609 Validation Accuracy: 0.567400\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss:     0.8520 Validation Accuracy: 0.574000\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss:     0.8138 Validation Accuracy: 0.575200\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss:     0.8549 Validation Accuracy: 0.569000\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss:     0.9304 Validation Accuracy: 0.570800\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     0.9268 Validation Accuracy: 0.568800\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss:     0.8276 Validation Accuracy: 0.566800\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss:     0.7990 Validation Accuracy: 0.565000\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss:     0.8668 Validation Accuracy: 0.564400\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss:     0.9372 Validation Accuracy: 0.560000\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     0.9395 Validation Accuracy: 0.568000\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss:     0.8562 Validation Accuracy: 0.569400\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss:     0.8084 Validation Accuracy: 0.569000\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss:     0.8460 Validation Accuracy: 0.570400\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss:     0.9188 Validation Accuracy: 0.568600\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     0.9209 Validation Accuracy: 0.567800\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss:     0.8055 Validation Accuracy: 0.566600\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss:     0.8165 Validation Accuracy: 0.568000\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss:     0.8733 Validation Accuracy: 0.566600\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss:     0.9275 Validation Accuracy: 0.567400\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     0.8957 Validation Accuracy: 0.575600\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss:     0.8296 Validation Accuracy: 0.572000\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss:     0.8186 Validation Accuracy: 0.568000\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss:     0.8577 Validation Accuracy: 0.569800\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss:     0.9237 Validation Accuracy: 0.561200\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     0.9122 Validation Accuracy: 0.568400\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss:     0.8322 Validation Accuracy: 0.569000\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss:     0.7866 Validation Accuracy: 0.569400\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss:     0.8606 Validation Accuracy: 0.567600\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss:     0.9324 Validation Accuracy: 0.563000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     0.9145 Validation Accuracy: 0.569600\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss:     0.8297 Validation Accuracy: 0.567200\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss:     0.7975 Validation Accuracy: 0.570200\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss:     0.8531 Validation Accuracy: 0.570600\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss:     0.9264 Validation Accuracy: 0.565600\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     0.9231 Validation Accuracy: 0.565800\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss:     0.8488 Validation Accuracy: 0.566600\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss:     0.8223 Validation Accuracy: 0.564200\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss:     0.8639 Validation Accuracy: 0.574200\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss:     0.9098 Validation Accuracy: 0.563200\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     0.9210 Validation Accuracy: 0.566800\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss:     0.8374 Validation Accuracy: 0.572400\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss:     0.8068 Validation Accuracy: 0.571400\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss:     0.8619 Validation Accuracy: 0.570000\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss:     0.9146 Validation Accuracy: 0.571000\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     0.9340 Validation Accuracy: 0.568000\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss:     0.8203 Validation Accuracy: 0.566800\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss:     0.7758 Validation Accuracy: 0.570200\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss:     0.8414 Validation Accuracy: 0.570200\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss:     0.9181 Validation Accuracy: 0.571400\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     0.9361 Validation Accuracy: 0.571000\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss:     0.8541 Validation Accuracy: 0.574400\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss:     0.7996 Validation Accuracy: 0.574000\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss:     0.8346 Validation Accuracy: 0.572600\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss:     0.9394 Validation Accuracy: 0.566600\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     0.9020 Validation Accuracy: 0.569800\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss:     0.8583 Validation Accuracy: 0.571200\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss:     0.7992 Validation Accuracy: 0.560600\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss:     0.8415 Validation Accuracy: 0.572200\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss:     0.9298 Validation Accuracy: 0.570400\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     0.9021 Validation Accuracy: 0.569200\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss:     0.8339 Validation Accuracy: 0.575200\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss:     0.8261 Validation Accuracy: 0.555000\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss:     0.8323 Validation Accuracy: 0.572200\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss:     0.9120 Validation Accuracy: 0.571400\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     0.9460 Validation Accuracy: 0.566600\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss:     0.8372 Validation Accuracy: 0.567800\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss:     0.8032 Validation Accuracy: 0.565800\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss:     0.8478 Validation Accuracy: 0.574400\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss:     0.9346 Validation Accuracy: 0.566600\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     0.9140 Validation Accuracy: 0.564200\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss:     0.8430 Validation Accuracy: 0.563600\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss:     0.7898 Validation Accuracy: 0.574200\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss:     0.8241 Validation Accuracy: 0.571200\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss:     0.9284 Validation Accuracy: 0.570600\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     0.9191 Validation Accuracy: 0.571200\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss:     0.8528 Validation Accuracy: 0.573400\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss:     0.7956 Validation Accuracy: 0.567600\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss:     0.8197 Validation Accuracy: 0.571800\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss:     0.9327 Validation Accuracy: 0.569400\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     0.9209 Validation Accuracy: 0.570400\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss:     0.8310 Validation Accuracy: 0.567800\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss:     0.8031 Validation Accuracy: 0.574200\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss:     0.8415 Validation Accuracy: 0.568000\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss:     0.9110 Validation Accuracy: 0.569200\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     0.9083 Validation Accuracy: 0.572000\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss:     0.8562 Validation Accuracy: 0.563000\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss:     0.8080 Validation Accuracy: 0.570400\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss:     0.8745 Validation Accuracy: 0.563200\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss:     0.9144 Validation Accuracy: 0.566600\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     0.9024 Validation Accuracy: 0.575800\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss:     0.8392 Validation Accuracy: 0.569000\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss:     0.8192 Validation Accuracy: 0.575600\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss:     0.8432 Validation Accuracy: 0.573200\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss:     0.9288 Validation Accuracy: 0.561400\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     0.9057 Validation Accuracy: 0.573200\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss:     0.8222 Validation Accuracy: 0.572200\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss:     0.7961 Validation Accuracy: 0.571000\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss:     0.8366 Validation Accuracy: 0.568400\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss:     0.9212 Validation Accuracy: 0.575600\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     0.9048 Validation Accuracy: 0.567600\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss:     0.8138 Validation Accuracy: 0.571200\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss:     0.7807 Validation Accuracy: 0.570400\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss:     0.8170 Validation Accuracy: 0.572600\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss:     0.9389 Validation Accuracy: 0.567400\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     0.9320 Validation Accuracy: 0.567000\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss:     0.8287 Validation Accuracy: 0.568400\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss:     0.8276 Validation Accuracy: 0.563000\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss:     0.8216 Validation Accuracy: 0.571600\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss:     0.9324 Validation Accuracy: 0.578600\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     0.9169 Validation Accuracy: 0.570000\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss:     0.8269 Validation Accuracy: 0.568800\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss:     0.7868 Validation Accuracy: 0.567800\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss:     0.8107 Validation Accuracy: 0.570200\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss:     0.9130 Validation Accuracy: 0.569800\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     0.9128 Validation Accuracy: 0.573800\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss:     0.8121 Validation Accuracy: 0.570200\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss:     0.7670 Validation Accuracy: 0.567800\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss:     0.8250 Validation Accuracy: 0.570800\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss:     0.8995 Validation Accuracy: 0.569400\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     0.9002 Validation Accuracy: 0.568400\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss:     0.8266 Validation Accuracy: 0.572800\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss:     0.7686 Validation Accuracy: 0.570000\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss:     0.8332 Validation Accuracy: 0.566800\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss:     0.9176 Validation Accuracy: 0.567600\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     0.9013 Validation Accuracy: 0.569400\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss:     0.8172 Validation Accuracy: 0.571400\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss:     0.7941 Validation Accuracy: 0.575200\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss:     0.8381 Validation Accuracy: 0.571200\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss:     0.8951 Validation Accuracy: 0.572400\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     0.9225 Validation Accuracy: 0.571800\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss:     0.8415 Validation Accuracy: 0.574600\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss:     0.7887 Validation Accuracy: 0.564400\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss:     0.8256 Validation Accuracy: 0.572000\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss:     0.9118 Validation Accuracy: 0.571800\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     0.9090 Validation Accuracy: 0.567800\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss:     0.8459 Validation Accuracy: 0.572400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237, CIFAR-10 Batch 3:  Loss:     0.7583 Validation Accuracy: 0.572200\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss:     0.8387 Validation Accuracy: 0.573600\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss:     0.9123 Validation Accuracy: 0.571200\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     0.9000 Validation Accuracy: 0.576000\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss:     0.8228 Validation Accuracy: 0.572600\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss:     0.7849 Validation Accuracy: 0.565800\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss:     0.8135 Validation Accuracy: 0.573000\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss:     0.9123 Validation Accuracy: 0.565000\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     0.9033 Validation Accuracy: 0.570000\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss:     0.8232 Validation Accuracy: 0.572800\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss:     0.7631 Validation Accuracy: 0.571200\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss:     0.8195 Validation Accuracy: 0.572200\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss:     0.9091 Validation Accuracy: 0.574000\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     0.9053 Validation Accuracy: 0.569200\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss:     0.8195 Validation Accuracy: 0.568600\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss:     0.7775 Validation Accuracy: 0.571800\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss:     0.8115 Validation Accuracy: 0.571200\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss:     0.9145 Validation Accuracy: 0.568600\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     0.9137 Validation Accuracy: 0.573400\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss:     0.8139 Validation Accuracy: 0.571200\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss:     0.7793 Validation Accuracy: 0.578000\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss:     0.8413 Validation Accuracy: 0.558600\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss:     0.8942 Validation Accuracy: 0.567400\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     0.9303 Validation Accuracy: 0.564800\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss:     0.8381 Validation Accuracy: 0.573200\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss:     0.7881 Validation Accuracy: 0.571200\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss:     0.8136 Validation Accuracy: 0.569200\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss:     0.8923 Validation Accuracy: 0.570200\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     0.9015 Validation Accuracy: 0.572400\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss:     0.8037 Validation Accuracy: 0.573000\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss:     0.7641 Validation Accuracy: 0.569200\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss:     0.8226 Validation Accuracy: 0.571600\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss:     0.9155 Validation Accuracy: 0.572800\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     0.9131 Validation Accuracy: 0.571600\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss:     0.8132 Validation Accuracy: 0.574200\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss:     0.7750 Validation Accuracy: 0.575200\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss:     0.8168 Validation Accuracy: 0.570200\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss:     0.9081 Validation Accuracy: 0.564200\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     0.9139 Validation Accuracy: 0.563800\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss:     0.8115 Validation Accuracy: 0.569400\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss:     0.7835 Validation Accuracy: 0.572800\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss:     0.8292 Validation Accuracy: 0.575600\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss:     0.9028 Validation Accuracy: 0.568000\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     0.9024 Validation Accuracy: 0.568200\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss:     0.8115 Validation Accuracy: 0.568400\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss:     0.7972 Validation Accuracy: 0.568400\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss:     0.8185 Validation Accuracy: 0.570200\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss:     0.9100 Validation Accuracy: 0.571400\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     0.9215 Validation Accuracy: 0.572200\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss:     0.7870 Validation Accuracy: 0.573200\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss:     0.8053 Validation Accuracy: 0.564200\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss:     0.8298 Validation Accuracy: 0.572800\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss:     0.8832 Validation Accuracy: 0.567000\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     0.9183 Validation Accuracy: 0.569600\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss:     0.7828 Validation Accuracy: 0.574200\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss:     0.7881 Validation Accuracy: 0.575800\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss:     0.8180 Validation Accuracy: 0.571000\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss:     0.9078 Validation Accuracy: 0.572200\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     0.8835 Validation Accuracy: 0.569200\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss:     0.8086 Validation Accuracy: 0.566000\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss:     0.7765 Validation Accuracy: 0.570000\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss:     0.8266 Validation Accuracy: 0.575000\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss:     0.9085 Validation Accuracy: 0.570600\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     0.8869 Validation Accuracy: 0.574800\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss:     0.8258 Validation Accuracy: 0.569600\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss:     0.7737 Validation Accuracy: 0.571800\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss:     0.8149 Validation Accuracy: 0.570800\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss:     0.8744 Validation Accuracy: 0.570600\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     0.9080 Validation Accuracy: 0.567800\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss:     0.7988 Validation Accuracy: 0.568000\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss:     0.7731 Validation Accuracy: 0.566600\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss:     0.8063 Validation Accuracy: 0.573600\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss:     0.8873 Validation Accuracy: 0.565000\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     0.8908 Validation Accuracy: 0.570800\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss:     0.7975 Validation Accuracy: 0.563600\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss:     0.7822 Validation Accuracy: 0.570800\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss:     0.8091 Validation Accuracy: 0.569800\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss:     0.8972 Validation Accuracy: 0.569600\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     0.9065 Validation Accuracy: 0.568800\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss:     0.8077 Validation Accuracy: 0.569000\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss:     0.7783 Validation Accuracy: 0.566800\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss:     0.8331 Validation Accuracy: 0.571600\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss:     0.9062 Validation Accuracy: 0.569200\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     0.9012 Validation Accuracy: 0.568400\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss:     0.8097 Validation Accuracy: 0.578800\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss:     0.8119 Validation Accuracy: 0.573200\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss:     0.8098 Validation Accuracy: 0.570400\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss:     0.8978 Validation Accuracy: 0.571800\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     0.8758 Validation Accuracy: 0.565800\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss:     0.8212 Validation Accuracy: 0.569800\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss:     0.7841 Validation Accuracy: 0.571400\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss:     0.8152 Validation Accuracy: 0.569400\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss:     0.8711 Validation Accuracy: 0.573600\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     0.8902 Validation Accuracy: 0.568800\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss:     0.8206 Validation Accuracy: 0.571800\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss:     0.7821 Validation Accuracy: 0.575800\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss:     0.8151 Validation Accuracy: 0.569600\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss:     0.8964 Validation Accuracy: 0.571600\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     0.9016 Validation Accuracy: 0.572400\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss:     0.8083 Validation Accuracy: 0.574800\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss:     0.7880 Validation Accuracy: 0.571400\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss:     0.8131 Validation Accuracy: 0.570600\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss:     0.9009 Validation Accuracy: 0.573000\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     0.8877 Validation Accuracy: 0.565800\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss:     0.8371 Validation Accuracy: 0.574800\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss:     0.7963 Validation Accuracy: 0.571800\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss:     0.8022 Validation Accuracy: 0.571400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258, CIFAR-10 Batch 5:  Loss:     0.8867 Validation Accuracy: 0.571400\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     0.9103 Validation Accuracy: 0.570800\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss:     0.8208 Validation Accuracy: 0.572600\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss:     0.7839 Validation Accuracy: 0.572200\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss:     0.7988 Validation Accuracy: 0.571800\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss:     0.9053 Validation Accuracy: 0.567600\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     0.8849 Validation Accuracy: 0.571600\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss:     0.8348 Validation Accuracy: 0.573600\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss:     0.7712 Validation Accuracy: 0.577200\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss:     0.7904 Validation Accuracy: 0.577200\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss:     0.9039 Validation Accuracy: 0.568000\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     0.8850 Validation Accuracy: 0.572800\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss:     0.8443 Validation Accuracy: 0.570400\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss:     0.7842 Validation Accuracy: 0.570200\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss:     0.8010 Validation Accuracy: 0.572400\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss:     0.8856 Validation Accuracy: 0.576600\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     0.8760 Validation Accuracy: 0.577200\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss:     0.8285 Validation Accuracy: 0.568400\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss:     0.7842 Validation Accuracy: 0.573400\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss:     0.8071 Validation Accuracy: 0.573200\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss:     0.8958 Validation Accuracy: 0.567600\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     0.8826 Validation Accuracy: 0.574400\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss:     0.8098 Validation Accuracy: 0.572600\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss:     0.7681 Validation Accuracy: 0.578600\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss:     0.8106 Validation Accuracy: 0.573000\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss:     0.8836 Validation Accuracy: 0.569400\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     0.8867 Validation Accuracy: 0.572400\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss:     0.8369 Validation Accuracy: 0.573400\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss:     0.7616 Validation Accuracy: 0.577200\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss:     0.7916 Validation Accuracy: 0.565600\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss:     0.8820 Validation Accuracy: 0.568000\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     0.9042 Validation Accuracy: 0.572200\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss:     0.8020 Validation Accuracy: 0.575200\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss:     0.7658 Validation Accuracy: 0.575400\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss:     0.8032 Validation Accuracy: 0.573000\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss:     0.8883 Validation Accuracy: 0.571200\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     0.8978 Validation Accuracy: 0.570600\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss:     0.8058 Validation Accuracy: 0.569200\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss:     0.7696 Validation Accuracy: 0.577600\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss:     0.8182 Validation Accuracy: 0.577200\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss:     0.8882 Validation Accuracy: 0.569800\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     0.8948 Validation Accuracy: 0.571600\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss:     0.8143 Validation Accuracy: 0.575600\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss:     0.7801 Validation Accuracy: 0.576200\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss:     0.7996 Validation Accuracy: 0.576200\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss:     0.8726 Validation Accuracy: 0.567400\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     0.9087 Validation Accuracy: 0.571600\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss:     0.8105 Validation Accuracy: 0.570800\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss:     0.7971 Validation Accuracy: 0.570000\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss:     0.7997 Validation Accuracy: 0.574600\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss:     0.8813 Validation Accuracy: 0.569600\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     0.8944 Validation Accuracy: 0.572400\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss:     0.8078 Validation Accuracy: 0.575200\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss:     0.7922 Validation Accuracy: 0.576000\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss:     0.7968 Validation Accuracy: 0.578200\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss:     0.8862 Validation Accuracy: 0.568800\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     0.9027 Validation Accuracy: 0.575000\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss:     0.8094 Validation Accuracy: 0.573200\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss:     0.8105 Validation Accuracy: 0.575000\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss:     0.7853 Validation Accuracy: 0.576000\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss:     0.8766 Validation Accuracy: 0.572200\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     0.8888 Validation Accuracy: 0.569800\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss:     0.7981 Validation Accuracy: 0.569800\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss:     0.7917 Validation Accuracy: 0.571400\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss:     0.7946 Validation Accuracy: 0.571000\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss:     0.8732 Validation Accuracy: 0.570600\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     0.8792 Validation Accuracy: 0.572400\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss:     0.7796 Validation Accuracy: 0.574000\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss:     0.8000 Validation Accuracy: 0.572000\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss:     0.7980 Validation Accuracy: 0.572200\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss:     0.8780 Validation Accuracy: 0.566800\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     0.8929 Validation Accuracy: 0.574000\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss:     0.7953 Validation Accuracy: 0.569000\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss:     0.8207 Validation Accuracy: 0.572600\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss:     0.8051 Validation Accuracy: 0.572400\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss:     0.8900 Validation Accuracy: 0.567200\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     0.8974 Validation Accuracy: 0.572800\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss:     0.7942 Validation Accuracy: 0.569400\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss:     0.7659 Validation Accuracy: 0.576400\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss:     0.7979 Validation Accuracy: 0.576800\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss:     0.8880 Validation Accuracy: 0.570200\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     0.8913 Validation Accuracy: 0.570600\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss:     0.8031 Validation Accuracy: 0.569400\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss:     0.7635 Validation Accuracy: 0.577800\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss:     0.7884 Validation Accuracy: 0.576800\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss:     0.8875 Validation Accuracy: 0.576200\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     0.8827 Validation Accuracy: 0.573200\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss:     0.7951 Validation Accuracy: 0.574400\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss:     0.7742 Validation Accuracy: 0.573200\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss:     0.8110 Validation Accuracy: 0.570000\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss:     0.8868 Validation Accuracy: 0.568800\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     0.8938 Validation Accuracy: 0.570000\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss:     0.7830 Validation Accuracy: 0.565400\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss:     0.7529 Validation Accuracy: 0.571400\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss:     0.7961 Validation Accuracy: 0.570600\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss:     0.8953 Validation Accuracy: 0.572600\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     0.8897 Validation Accuracy: 0.570600\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss:     0.7891 Validation Accuracy: 0.572800\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss:     0.7883 Validation Accuracy: 0.573800\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss:     0.7769 Validation Accuracy: 0.573000\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss:     0.8632 Validation Accuracy: 0.573400\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     0.9232 Validation Accuracy: 0.564000\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss:     0.7919 Validation Accuracy: 0.570000\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss:     0.7684 Validation Accuracy: 0.571400\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss:     0.7721 Validation Accuracy: 0.567600\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss:     0.8685 Validation Accuracy: 0.572200\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     0.8848 Validation Accuracy: 0.579400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280, CIFAR-10 Batch 2:  Loss:     0.7639 Validation Accuracy: 0.575400\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss:     0.7574 Validation Accuracy: 0.569400\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss:     0.7743 Validation Accuracy: 0.575000\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss:     0.8845 Validation Accuracy: 0.570600\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     0.9025 Validation Accuracy: 0.574400\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss:     0.8031 Validation Accuracy: 0.575400\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss:     0.7822 Validation Accuracy: 0.575400\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss:     0.7843 Validation Accuracy: 0.573200\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss:     0.8899 Validation Accuracy: 0.570800\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     0.8828 Validation Accuracy: 0.570000\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss:     0.7825 Validation Accuracy: 0.570400\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss:     0.7860 Validation Accuracy: 0.571600\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss:     0.7839 Validation Accuracy: 0.576400\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss:     0.9006 Validation Accuracy: 0.575800\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     0.9136 Validation Accuracy: 0.572400\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss:     0.7566 Validation Accuracy: 0.574000\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss:     0.7789 Validation Accuracy: 0.581800\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss:     0.7949 Validation Accuracy: 0.576000\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss:     0.8989 Validation Accuracy: 0.573600\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     0.8665 Validation Accuracy: 0.574200\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss:     0.7509 Validation Accuracy: 0.573600\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss:     0.7635 Validation Accuracy: 0.571600\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss:     0.7910 Validation Accuracy: 0.572400\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss:     0.8661 Validation Accuracy: 0.577800\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     0.8806 Validation Accuracy: 0.572200\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss:     0.7665 Validation Accuracy: 0.574800\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss:     0.7580 Validation Accuracy: 0.575400\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss:     0.7751 Validation Accuracy: 0.573400\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss:     0.8744 Validation Accuracy: 0.575000\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     0.9020 Validation Accuracy: 0.573000\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss:     0.7682 Validation Accuracy: 0.571000\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss:     0.7499 Validation Accuracy: 0.571600\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss:     0.7847 Validation Accuracy: 0.571800\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss:     0.8819 Validation Accuracy: 0.574200\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     0.8849 Validation Accuracy: 0.569000\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss:     0.7806 Validation Accuracy: 0.574800\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss:     0.7476 Validation Accuracy: 0.579000\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss:     0.7861 Validation Accuracy: 0.575600\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss:     0.8689 Validation Accuracy: 0.577400\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     0.8861 Validation Accuracy: 0.576600\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss:     0.7928 Validation Accuracy: 0.575200\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss:     0.7706 Validation Accuracy: 0.575400\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss:     0.7785 Validation Accuracy: 0.575000\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss:     0.8637 Validation Accuracy: 0.572600\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     0.8844 Validation Accuracy: 0.577400\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss:     0.7930 Validation Accuracy: 0.575600\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss:     0.7379 Validation Accuracy: 0.571600\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss:     0.7632 Validation Accuracy: 0.580200\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss:     0.8713 Validation Accuracy: 0.573600\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     0.8902 Validation Accuracy: 0.571400\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss:     0.7634 Validation Accuracy: 0.575000\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss:     0.7670 Validation Accuracy: 0.575600\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss:     0.7592 Validation Accuracy: 0.575600\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss:     0.8710 Validation Accuracy: 0.575200\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     0.9101 Validation Accuracy: 0.573600\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss:     0.7980 Validation Accuracy: 0.567800\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss:     0.7488 Validation Accuracy: 0.573000\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss:     0.7660 Validation Accuracy: 0.574800\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss:     0.8607 Validation Accuracy: 0.573600\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     0.9245 Validation Accuracy: 0.563400\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss:     0.7975 Validation Accuracy: 0.575800\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss:     0.7449 Validation Accuracy: 0.573800\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss:     0.7869 Validation Accuracy: 0.572800\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss:     0.8846 Validation Accuracy: 0.570800\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     0.8801 Validation Accuracy: 0.571600\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss:     0.7773 Validation Accuracy: 0.574200\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss:     0.7743 Validation Accuracy: 0.573600\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss:     0.7993 Validation Accuracy: 0.570400\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss:     0.8607 Validation Accuracy: 0.573200\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     0.9085 Validation Accuracy: 0.573000\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss:     0.7720 Validation Accuracy: 0.579400\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss:     0.7592 Validation Accuracy: 0.574200\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss:     0.7956 Validation Accuracy: 0.565800\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss:     0.8652 Validation Accuracy: 0.577800\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     0.9074 Validation Accuracy: 0.571800\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss:     0.7892 Validation Accuracy: 0.576000\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss:     0.7647 Validation Accuracy: 0.572800\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss:     0.7736 Validation Accuracy: 0.575800\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss:     0.8649 Validation Accuracy: 0.569800\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     0.8883 Validation Accuracy: 0.575600\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss:     0.7904 Validation Accuracy: 0.574200\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss:     0.7523 Validation Accuracy: 0.577400\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss:     0.7538 Validation Accuracy: 0.571600\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss:     0.8653 Validation Accuracy: 0.568600\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     0.8941 Validation Accuracy: 0.570200\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss:     0.7883 Validation Accuracy: 0.569200\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss:     0.7689 Validation Accuracy: 0.573600\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss:     0.7616 Validation Accuracy: 0.578400\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss:     0.8651 Validation Accuracy: 0.569000\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     0.8784 Validation Accuracy: 0.575000\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss:     0.7779 Validation Accuracy: 0.569800\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss:     0.7826 Validation Accuracy: 0.576200\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss:     0.7795 Validation Accuracy: 0.575600\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss:     0.8515 Validation Accuracy: 0.571600\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     0.8868 Validation Accuracy: 0.571000\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss:     0.7835 Validation Accuracy: 0.573800\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss:     0.7857 Validation Accuracy: 0.572600\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss:     0.7668 Validation Accuracy: 0.575200\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss:     0.8521 Validation Accuracy: 0.575600\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     0.8727 Validation Accuracy: 0.569400\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss:     0.7799 Validation Accuracy: 0.573800\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss:     0.7690 Validation Accuracy: 0.571000\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss:     0.7793 Validation Accuracy: 0.571600\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss:     0.8583 Validation Accuracy: 0.570400\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     0.9059 Validation Accuracy: 0.570800\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss:     0.7773 Validation Accuracy: 0.572600\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss:     0.7628 Validation Accuracy: 0.572600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301, CIFAR-10 Batch 4:  Loss:     0.7796 Validation Accuracy: 0.568200\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss:     0.8756 Validation Accuracy: 0.572400\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     0.8999 Validation Accuracy: 0.570000\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss:     0.7752 Validation Accuracy: 0.566600\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss:     0.7625 Validation Accuracy: 0.568000\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss:     0.7703 Validation Accuracy: 0.574400\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss:     0.8700 Validation Accuracy: 0.574400\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     0.8850 Validation Accuracy: 0.571800\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss:     0.7774 Validation Accuracy: 0.570800\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss:     0.7808 Validation Accuracy: 0.577000\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss:     0.7673 Validation Accuracy: 0.574800\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss:     0.8644 Validation Accuracy: 0.574600\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     0.8789 Validation Accuracy: 0.568200\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss:     0.8059 Validation Accuracy: 0.568600\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss:     0.7946 Validation Accuracy: 0.570600\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss:     0.7721 Validation Accuracy: 0.576200\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss:     0.8584 Validation Accuracy: 0.567800\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     0.8828 Validation Accuracy: 0.576400\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss:     0.7979 Validation Accuracy: 0.571400\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss:     0.7460 Validation Accuracy: 0.572000\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss:     0.7620 Validation Accuracy: 0.574400\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss:     0.8705 Validation Accuracy: 0.571000\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     0.8975 Validation Accuracy: 0.569600\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss:     0.8003 Validation Accuracy: 0.571000\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss:     0.7636 Validation Accuracy: 0.574000\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss:     0.7667 Validation Accuracy: 0.579000\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss:     0.8395 Validation Accuracy: 0.574400\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     0.8895 Validation Accuracy: 0.573000\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss:     0.7880 Validation Accuracy: 0.578000\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss:     0.7672 Validation Accuracy: 0.569200\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss:     0.7718 Validation Accuracy: 0.579000\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss:     0.8663 Validation Accuracy: 0.573600\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     0.8942 Validation Accuracy: 0.572000\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss:     0.7822 Validation Accuracy: 0.571800\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss:     0.7616 Validation Accuracy: 0.576600\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss:     0.7921 Validation Accuracy: 0.573200\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss:     0.8644 Validation Accuracy: 0.570600\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     0.8983 Validation Accuracy: 0.575600\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss:     0.7721 Validation Accuracy: 0.570200\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss:     0.7584 Validation Accuracy: 0.570000\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss:     0.7753 Validation Accuracy: 0.576000\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss:     0.8535 Validation Accuracy: 0.577000\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     0.9198 Validation Accuracy: 0.568400\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss:     0.7767 Validation Accuracy: 0.570000\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss:     0.7415 Validation Accuracy: 0.576000\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss:     0.7731 Validation Accuracy: 0.576600\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss:     0.8504 Validation Accuracy: 0.569600\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     0.8990 Validation Accuracy: 0.568600\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss:     0.7860 Validation Accuracy: 0.570800\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss:     0.7766 Validation Accuracy: 0.576400\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss:     0.7660 Validation Accuracy: 0.571000\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss:     0.8483 Validation Accuracy: 0.574800\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     0.9254 Validation Accuracy: 0.571600\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss:     0.7802 Validation Accuracy: 0.575600\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss:     0.7626 Validation Accuracy: 0.573800\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss:     0.7646 Validation Accuracy: 0.576400\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss:     0.8546 Validation Accuracy: 0.565600\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     0.8727 Validation Accuracy: 0.569200\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss:     0.7765 Validation Accuracy: 0.573600\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss:     0.7787 Validation Accuracy: 0.573400\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss:     0.7766 Validation Accuracy: 0.573800\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss:     0.8460 Validation Accuracy: 0.572000\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     0.8795 Validation Accuracy: 0.571400\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss:     0.7780 Validation Accuracy: 0.573800\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss:     0.7555 Validation Accuracy: 0.571200\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss:     0.7725 Validation Accuracy: 0.575000\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss:     0.8624 Validation Accuracy: 0.573400\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     0.8877 Validation Accuracy: 0.573400\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss:     0.7905 Validation Accuracy: 0.567600\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss:     0.7621 Validation Accuracy: 0.569600\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss:     0.7599 Validation Accuracy: 0.578000\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss:     0.8389 Validation Accuracy: 0.571800\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     0.8991 Validation Accuracy: 0.574000\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss:     0.7715 Validation Accuracy: 0.577200\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss:     0.7662 Validation Accuracy: 0.575800\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss:     0.7627 Validation Accuracy: 0.575800\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss:     0.8541 Validation Accuracy: 0.572800\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     0.8871 Validation Accuracy: 0.571400\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss:     0.7578 Validation Accuracy: 0.575400\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss:     0.7744 Validation Accuracy: 0.575600\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss:     0.7566 Validation Accuracy: 0.574600\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss:     0.8707 Validation Accuracy: 0.570200\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     0.8976 Validation Accuracy: 0.572000\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss:     0.7418 Validation Accuracy: 0.570000\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss:     0.7667 Validation Accuracy: 0.573000\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss:     0.7704 Validation Accuracy: 0.570400\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss:     0.8375 Validation Accuracy: 0.578600\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     0.8870 Validation Accuracy: 0.573400\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss:     0.7612 Validation Accuracy: 0.572200\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss:     0.7377 Validation Accuracy: 0.577800\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss:     0.7604 Validation Accuracy: 0.574400\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss:     0.8585 Validation Accuracy: 0.575800\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     0.8984 Validation Accuracy: 0.571800\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss:     0.7644 Validation Accuracy: 0.571600\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss:     0.7685 Validation Accuracy: 0.571400\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss:     0.7440 Validation Accuracy: 0.571400\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss:     0.8765 Validation Accuracy: 0.571400\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     0.9141 Validation Accuracy: 0.563200\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss:     0.7607 Validation Accuracy: 0.573600\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss:     0.7461 Validation Accuracy: 0.572600\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss:     0.7688 Validation Accuracy: 0.577200\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss:     0.8635 Validation Accuracy: 0.576800\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     0.8564 Validation Accuracy: 0.574200\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss:     0.7707 Validation Accuracy: 0.567200\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss:     0.7595 Validation Accuracy: 0.573400\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss:     0.7771 Validation Accuracy: 0.575200\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss:     0.8329 Validation Accuracy: 0.576600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     0.8891 Validation Accuracy: 0.571400\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss:     0.7836 Validation Accuracy: 0.571200\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss:     0.7290 Validation Accuracy: 0.578600\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss:     0.8157 Validation Accuracy: 0.563400\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss:     0.8534 Validation Accuracy: 0.575800\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     0.8848 Validation Accuracy: 0.570200\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss:     0.7648 Validation Accuracy: 0.572400\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss:     0.7375 Validation Accuracy: 0.579600\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss:     0.7771 Validation Accuracy: 0.573400\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss:     0.8496 Validation Accuracy: 0.566800\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     0.9108 Validation Accuracy: 0.566800\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss:     0.7931 Validation Accuracy: 0.571800\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss:     0.7596 Validation Accuracy: 0.580400\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss:     0.7620 Validation Accuracy: 0.574000\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss:     0.8565 Validation Accuracy: 0.576600\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     0.8837 Validation Accuracy: 0.569800\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss:     0.7681 Validation Accuracy: 0.571400\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss:     0.7569 Validation Accuracy: 0.571400\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss:     0.7897 Validation Accuracy: 0.575400\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss:     0.8765 Validation Accuracy: 0.573600\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     0.8731 Validation Accuracy: 0.574800\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss:     0.7473 Validation Accuracy: 0.577200\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss:     0.7434 Validation Accuracy: 0.573200\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss:     0.7666 Validation Accuracy: 0.569400\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss:     0.8525 Validation Accuracy: 0.573200\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     0.8803 Validation Accuracy: 0.573800\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss:     0.7637 Validation Accuracy: 0.576800\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss:     0.7131 Validation Accuracy: 0.576200\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss:     0.7695 Validation Accuracy: 0.574800\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss:     0.8661 Validation Accuracy: 0.571800\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     0.8728 Validation Accuracy: 0.570800\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss:     0.7526 Validation Accuracy: 0.571800\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss:     0.7516 Validation Accuracy: 0.569800\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss:     0.7555 Validation Accuracy: 0.579000\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss:     0.8659 Validation Accuracy: 0.574400\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     0.8727 Validation Accuracy: 0.573800\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss:     0.7699 Validation Accuracy: 0.570200\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss:     0.7374 Validation Accuracy: 0.578000\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss:     0.7592 Validation Accuracy: 0.572600\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss:     0.8393 Validation Accuracy: 0.575600\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     0.8916 Validation Accuracy: 0.572000\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss:     0.7547 Validation Accuracy: 0.573600\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss:     0.7421 Validation Accuracy: 0.572200\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss:     0.7573 Validation Accuracy: 0.576000\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss:     0.8554 Validation Accuracy: 0.569800\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     0.8926 Validation Accuracy: 0.568600\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss:     0.7649 Validation Accuracy: 0.568400\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss:     0.7371 Validation Accuracy: 0.578000\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss:     0.7550 Validation Accuracy: 0.571400\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss:     0.8519 Validation Accuracy: 0.568200\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     0.8992 Validation Accuracy: 0.562600\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss:     0.7516 Validation Accuracy: 0.573400\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss:     0.7555 Validation Accuracy: 0.574200\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss:     0.7679 Validation Accuracy: 0.575800\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss:     0.8425 Validation Accuracy: 0.571200\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     0.8751 Validation Accuracy: 0.572200\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss:     0.7652 Validation Accuracy: 0.575200\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss:     0.7403 Validation Accuracy: 0.569200\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss:     0.7596 Validation Accuracy: 0.573200\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss:     0.8317 Validation Accuracy: 0.573400\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     0.8620 Validation Accuracy: 0.571800\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss:     0.7558 Validation Accuracy: 0.569800\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss:     0.7537 Validation Accuracy: 0.568800\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss:     0.7645 Validation Accuracy: 0.572800\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss:     0.8379 Validation Accuracy: 0.572200\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     0.8811 Validation Accuracy: 0.572000\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss:     0.7606 Validation Accuracy: 0.568800\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss:     0.7491 Validation Accuracy: 0.576200\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss:     0.7381 Validation Accuracy: 0.577400\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss:     0.8585 Validation Accuracy: 0.574800\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     0.8563 Validation Accuracy: 0.572800\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss:     0.7460 Validation Accuracy: 0.577800\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss:     0.7532 Validation Accuracy: 0.576200\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss:     0.7385 Validation Accuracy: 0.572000\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss:     0.8502 Validation Accuracy: 0.574000\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     0.8688 Validation Accuracy: 0.576600\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss:     0.7707 Validation Accuracy: 0.576800\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss:     0.7563 Validation Accuracy: 0.579200\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss:     0.7576 Validation Accuracy: 0.574000\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss:     0.8713 Validation Accuracy: 0.575600\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     0.8844 Validation Accuracy: 0.569800\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss:     0.7427 Validation Accuracy: 0.569600\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss:     0.7422 Validation Accuracy: 0.573800\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss:     0.7628 Validation Accuracy: 0.572400\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss:     0.8529 Validation Accuracy: 0.572400\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     0.8769 Validation Accuracy: 0.574400\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss:     0.7578 Validation Accuracy: 0.574000\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss:     0.7537 Validation Accuracy: 0.574800\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss:     0.7705 Validation Accuracy: 0.572400\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss:     0.8434 Validation Accuracy: 0.574000\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     0.8856 Validation Accuracy: 0.569600\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss:     0.7691 Validation Accuracy: 0.575000\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss:     0.7340 Validation Accuracy: 0.573400\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss:     0.7456 Validation Accuracy: 0.575600\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss:     0.8449 Validation Accuracy: 0.576200\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     0.8737 Validation Accuracy: 0.571600\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss:     0.7509 Validation Accuracy: 0.576800\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss:     0.7461 Validation Accuracy: 0.574200\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss:     0.7723 Validation Accuracy: 0.578600\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss:     0.8482 Validation Accuracy: 0.572800\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     0.8920 Validation Accuracy: 0.572600\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss:     0.7653 Validation Accuracy: 0.571800\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss:     0.7413 Validation Accuracy: 0.574600\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss:     0.7788 Validation Accuracy: 0.574600\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss:     0.8452 Validation Accuracy: 0.576200\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     0.8814 Validation Accuracy: 0.579600\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss:     0.7720 Validation Accuracy: 0.576000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344, CIFAR-10 Batch 3:  Loss:     0.7522 Validation Accuracy: 0.571600\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss:     0.7588 Validation Accuracy: 0.572400\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss:     0.8403 Validation Accuracy: 0.569000\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     0.8846 Validation Accuracy: 0.571600\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss:     0.7683 Validation Accuracy: 0.568600\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss:     0.7491 Validation Accuracy: 0.579600\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss:     0.7627 Validation Accuracy: 0.578000\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss:     0.8437 Validation Accuracy: 0.571400\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     0.8832 Validation Accuracy: 0.571400\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss:     0.7794 Validation Accuracy: 0.573600\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss:     0.7749 Validation Accuracy: 0.576400\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss:     0.7561 Validation Accuracy: 0.572600\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss:     0.8477 Validation Accuracy: 0.572800\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     0.8697 Validation Accuracy: 0.571800\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss:     0.7608 Validation Accuracy: 0.577200\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss:     0.7533 Validation Accuracy: 0.573200\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss:     0.7415 Validation Accuracy: 0.575600\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss:     0.8574 Validation Accuracy: 0.570800\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     0.8733 Validation Accuracy: 0.573400\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss:     0.7705 Validation Accuracy: 0.571400\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss:     0.7701 Validation Accuracy: 0.567800\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss:     0.7614 Validation Accuracy: 0.575600\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss:     0.8347 Validation Accuracy: 0.573800\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     0.8681 Validation Accuracy: 0.571000\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss:     0.7541 Validation Accuracy: 0.581600\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss:     0.7315 Validation Accuracy: 0.576800\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss:     0.7466 Validation Accuracy: 0.573400\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss:     0.8287 Validation Accuracy: 0.574800\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     0.8728 Validation Accuracy: 0.573200\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss:     0.7643 Validation Accuracy: 0.576000\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss:     0.7533 Validation Accuracy: 0.578400\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss:     0.7434 Validation Accuracy: 0.574600\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss:     0.8366 Validation Accuracy: 0.575800\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     0.8687 Validation Accuracy: 0.568200\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss:     0.7820 Validation Accuracy: 0.575000\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss:     0.7408 Validation Accuracy: 0.573000\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss:     0.7447 Validation Accuracy: 0.573800\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss:     0.8323 Validation Accuracy: 0.571200\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     0.8808 Validation Accuracy: 0.571600\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss:     0.7710 Validation Accuracy: 0.567600\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss:     0.7316 Validation Accuracy: 0.573000\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss:     0.7542 Validation Accuracy: 0.571600\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss:     0.8422 Validation Accuracy: 0.571400\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     0.8935 Validation Accuracy: 0.567600\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss:     0.7657 Validation Accuracy: 0.574200\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss:     0.7465 Validation Accuracy: 0.568800\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss:     0.7539 Validation Accuracy: 0.570800\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss:     0.8594 Validation Accuracy: 0.574800\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     0.9148 Validation Accuracy: 0.573800\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss:     0.7947 Validation Accuracy: 0.568600\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss:     0.7469 Validation Accuracy: 0.569200\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss:     0.7455 Validation Accuracy: 0.574400\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss:     0.8513 Validation Accuracy: 0.572000\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     0.8996 Validation Accuracy: 0.577800\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss:     0.7605 Validation Accuracy: 0.574600\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss:     0.7565 Validation Accuracy: 0.572400\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss:     0.7480 Validation Accuracy: 0.570800\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss:     0.8607 Validation Accuracy: 0.568800\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     0.8850 Validation Accuracy: 0.567600\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss:     0.7427 Validation Accuracy: 0.573200\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss:     0.7495 Validation Accuracy: 0.574000\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss:     0.7479 Validation Accuracy: 0.569200\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss:     0.8566 Validation Accuracy: 0.571200\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     0.8997 Validation Accuracy: 0.576400\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss:     0.7497 Validation Accuracy: 0.573200\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss:     0.7595 Validation Accuracy: 0.573600\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss:     0.7316 Validation Accuracy: 0.576400\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss:     0.8403 Validation Accuracy: 0.575400\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     0.8906 Validation Accuracy: 0.567200\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss:     0.7716 Validation Accuracy: 0.570400\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss:     0.7104 Validation Accuracy: 0.572200\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss:     0.7361 Validation Accuracy: 0.573200\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss:     0.8326 Validation Accuracy: 0.566200\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     0.8809 Validation Accuracy: 0.569400\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss:     0.7669 Validation Accuracy: 0.572000\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss:     0.7278 Validation Accuracy: 0.569600\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss:     0.7356 Validation Accuracy: 0.575600\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss:     0.8562 Validation Accuracy: 0.572600\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     0.8863 Validation Accuracy: 0.572000\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss:     0.7727 Validation Accuracy: 0.571400\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss:     0.7437 Validation Accuracy: 0.572000\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss:     0.7535 Validation Accuracy: 0.575600\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss:     0.8393 Validation Accuracy: 0.576200\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     0.9030 Validation Accuracy: 0.566200\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss:     0.7673 Validation Accuracy: 0.566000\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss:     0.7392 Validation Accuracy: 0.574600\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss:     0.7437 Validation Accuracy: 0.573200\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss:     0.8758 Validation Accuracy: 0.572600\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     0.8763 Validation Accuracy: 0.566400\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss:     0.7398 Validation Accuracy: 0.568200\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss:     0.7435 Validation Accuracy: 0.569400\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss:     0.7478 Validation Accuracy: 0.572800\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss:     0.8467 Validation Accuracy: 0.573000\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     0.8796 Validation Accuracy: 0.571800\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss:     0.7457 Validation Accuracy: 0.573800\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss:     0.7371 Validation Accuracy: 0.569600\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss:     0.7430 Validation Accuracy: 0.573200\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss:     0.8412 Validation Accuracy: 0.573400\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     0.8817 Validation Accuracy: 0.568400\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss:     0.7671 Validation Accuracy: 0.567600\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss:     0.7402 Validation Accuracy: 0.569000\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss:     0.7273 Validation Accuracy: 0.576600\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss:     0.8316 Validation Accuracy: 0.577200\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     0.8743 Validation Accuracy: 0.568200\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss:     0.7655 Validation Accuracy: 0.574800\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss:     0.7344 Validation Accuracy: 0.577400\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss:     0.7580 Validation Accuracy: 0.572800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365, CIFAR-10 Batch 5:  Loss:     0.8443 Validation Accuracy: 0.572400\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     0.8986 Validation Accuracy: 0.566000\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss:     0.7611 Validation Accuracy: 0.572000\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss:     0.7423 Validation Accuracy: 0.568000\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss:     0.7429 Validation Accuracy: 0.575800\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss:     0.8478 Validation Accuracy: 0.577600\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     0.8882 Validation Accuracy: 0.570400\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss:     0.7611 Validation Accuracy: 0.572800\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss:     0.7195 Validation Accuracy: 0.571200\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss:     0.7444 Validation Accuracy: 0.573400\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss:     0.8501 Validation Accuracy: 0.575800\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     0.8878 Validation Accuracy: 0.568000\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss:     0.7599 Validation Accuracy: 0.569400\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss:     0.7077 Validation Accuracy: 0.574800\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss:     0.7334 Validation Accuracy: 0.571800\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss:     0.8471 Validation Accuracy: 0.571400\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     0.8701 Validation Accuracy: 0.570200\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss:     0.7623 Validation Accuracy: 0.570200\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss:     0.7329 Validation Accuracy: 0.568800\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss:     0.7486 Validation Accuracy: 0.574200\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss:     0.8322 Validation Accuracy: 0.574600\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     0.8840 Validation Accuracy: 0.565000\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss:     0.7453 Validation Accuracy: 0.575800\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss:     0.7374 Validation Accuracy: 0.573800\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss:     0.7383 Validation Accuracy: 0.571400\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss:     0.8690 Validation Accuracy: 0.571400\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     0.8936 Validation Accuracy: 0.572400\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss:     0.7680 Validation Accuracy: 0.571400\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss:     0.7452 Validation Accuracy: 0.570800\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss:     0.7466 Validation Accuracy: 0.571600\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss:     0.8259 Validation Accuracy: 0.571200\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     0.8793 Validation Accuracy: 0.571200\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss:     0.7409 Validation Accuracy: 0.570200\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss:     0.7532 Validation Accuracy: 0.573400\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss:     0.7595 Validation Accuracy: 0.573600\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss:     0.8267 Validation Accuracy: 0.568200\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     0.8519 Validation Accuracy: 0.574600\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss:     0.7406 Validation Accuracy: 0.573400\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss:     0.7324 Validation Accuracy: 0.574600\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss:     0.7502 Validation Accuracy: 0.571600\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss:     0.8142 Validation Accuracy: 0.575200\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     0.8665 Validation Accuracy: 0.573400\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss:     0.7434 Validation Accuracy: 0.575000\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss:     0.7290 Validation Accuracy: 0.572200\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss:     0.7634 Validation Accuracy: 0.572800\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss:     0.8172 Validation Accuracy: 0.576800\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     0.8735 Validation Accuracy: 0.572000\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss:     0.7558 Validation Accuracy: 0.573400\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss:     0.7169 Validation Accuracy: 0.571800\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss:     0.7469 Validation Accuracy: 0.571000\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss:     0.8777 Validation Accuracy: 0.568400\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     0.9012 Validation Accuracy: 0.569600\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss:     0.7549 Validation Accuracy: 0.574600\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss:     0.7317 Validation Accuracy: 0.572200\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss:     0.7525 Validation Accuracy: 0.568800\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss:     0.8992 Validation Accuracy: 0.572000\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     0.8638 Validation Accuracy: 0.573600\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss:     0.7695 Validation Accuracy: 0.567400\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss:     0.7309 Validation Accuracy: 0.566800\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss:     0.7391 Validation Accuracy: 0.570000\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss:     0.8345 Validation Accuracy: 0.571400\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     0.8934 Validation Accuracy: 0.567600\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss:     0.7468 Validation Accuracy: 0.571000\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss:     0.7106 Validation Accuracy: 0.573000\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss:     0.7430 Validation Accuracy: 0.574000\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss:     0.8482 Validation Accuracy: 0.570800\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     0.8565 Validation Accuracy: 0.572800\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss:     0.7281 Validation Accuracy: 0.572800\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss:     0.7082 Validation Accuracy: 0.572600\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss:     0.7629 Validation Accuracy: 0.572800\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss:     0.8347 Validation Accuracy: 0.571200\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     0.8601 Validation Accuracy: 0.574000\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss:     0.7526 Validation Accuracy: 0.572000\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss:     0.7227 Validation Accuracy: 0.572400\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss:     0.7603 Validation Accuracy: 0.570400\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss:     0.8328 Validation Accuracy: 0.572200\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     0.8902 Validation Accuracy: 0.565200\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss:     0.7495 Validation Accuracy: 0.575600\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss:     0.7449 Validation Accuracy: 0.571400\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss:     0.7620 Validation Accuracy: 0.571400\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss:     0.8159 Validation Accuracy: 0.577600\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     0.9279 Validation Accuracy: 0.567200\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss:     0.7476 Validation Accuracy: 0.574400\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss:     0.7290 Validation Accuracy: 0.576800\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss:     0.7455 Validation Accuracy: 0.575600\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss:     0.8333 Validation Accuracy: 0.570000\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     0.8921 Validation Accuracy: 0.570600\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss:     0.7479 Validation Accuracy: 0.571000\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss:     0.7273 Validation Accuracy: 0.570000\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss:     0.7685 Validation Accuracy: 0.574200\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss:     0.8418 Validation Accuracy: 0.572200\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     0.9064 Validation Accuracy: 0.565800\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss:     0.7598 Validation Accuracy: 0.573000\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss:     0.7113 Validation Accuracy: 0.574000\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss:     0.7603 Validation Accuracy: 0.565000\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss:     0.8206 Validation Accuracy: 0.574800\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     0.8949 Validation Accuracy: 0.567000\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss:     0.7635 Validation Accuracy: 0.572400\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss:     0.6980 Validation Accuracy: 0.572200\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss:     0.7578 Validation Accuracy: 0.571000\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss:     0.8300 Validation Accuracy: 0.572200\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     0.8651 Validation Accuracy: 0.574600\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss:     0.7563 Validation Accuracy: 0.572200\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss:     0.7226 Validation Accuracy: 0.575400\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss:     0.7673 Validation Accuracy: 0.572800\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss:     0.8900 Validation Accuracy: 0.570600\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     0.8775 Validation Accuracy: 0.571800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387, CIFAR-10 Batch 2:  Loss:     0.7674 Validation Accuracy: 0.574600\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss:     0.7304 Validation Accuracy: 0.575200\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss:     0.7552 Validation Accuracy: 0.573800\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss:     0.8210 Validation Accuracy: 0.576400\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     0.8961 Validation Accuracy: 0.566400\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss:     0.7768 Validation Accuracy: 0.572000\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss:     0.7017 Validation Accuracy: 0.574600\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss:     0.7622 Validation Accuracy: 0.569600\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss:     0.8494 Validation Accuracy: 0.571000\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     0.8771 Validation Accuracy: 0.568600\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss:     0.7521 Validation Accuracy: 0.573600\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss:     0.7191 Validation Accuracy: 0.576200\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss:     0.7447 Validation Accuracy: 0.571400\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss:     0.8588 Validation Accuracy: 0.572800\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     0.8636 Validation Accuracy: 0.567600\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss:     0.7455 Validation Accuracy: 0.571000\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss:     0.7226 Validation Accuracy: 0.571400\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss:     0.7462 Validation Accuracy: 0.574200\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss:     0.8194 Validation Accuracy: 0.573600\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     0.8717 Validation Accuracy: 0.563000\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss:     0.7580 Validation Accuracy: 0.568800\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss:     0.6980 Validation Accuracy: 0.570600\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss:     0.7449 Validation Accuracy: 0.571000\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss:     0.8263 Validation Accuracy: 0.573000\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     0.8827 Validation Accuracy: 0.568000\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss:     0.7479 Validation Accuracy: 0.566800\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss:     0.7409 Validation Accuracy: 0.569000\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss:     0.7462 Validation Accuracy: 0.575600\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss:     0.8460 Validation Accuracy: 0.577000\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     0.8735 Validation Accuracy: 0.566800\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss:     0.7437 Validation Accuracy: 0.575000\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss:     0.7209 Validation Accuracy: 0.570600\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss:     0.7615 Validation Accuracy: 0.571600\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss:     0.8542 Validation Accuracy: 0.570400\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     0.8758 Validation Accuracy: 0.568200\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss:     0.7648 Validation Accuracy: 0.570400\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss:     0.7259 Validation Accuracy: 0.571600\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss:     0.7493 Validation Accuracy: 0.572400\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss:     0.8271 Validation Accuracy: 0.572600\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     0.8921 Validation Accuracy: 0.568600\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss:     0.7570 Validation Accuracy: 0.574800\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss:     0.6994 Validation Accuracy: 0.577200\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss:     0.7509 Validation Accuracy: 0.572600\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss:     0.8367 Validation Accuracy: 0.575400\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     0.8608 Validation Accuracy: 0.572600\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss:     0.7600 Validation Accuracy: 0.571000\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss:     0.6970 Validation Accuracy: 0.575800\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss:     0.7373 Validation Accuracy: 0.572400\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss:     0.8267 Validation Accuracy: 0.574000\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     0.8920 Validation Accuracy: 0.565600\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss:     0.7337 Validation Accuracy: 0.563400\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss:     0.7225 Validation Accuracy: 0.573200\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss:     0.7442 Validation Accuracy: 0.570800\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss:     0.8461 Validation Accuracy: 0.568200\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     0.8954 Validation Accuracy: 0.568000\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss:     0.7258 Validation Accuracy: 0.571200\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss:     0.7171 Validation Accuracy: 0.572000\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss:     0.7339 Validation Accuracy: 0.569200\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss:     0.8353 Validation Accuracy: 0.576000\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     0.8983 Validation Accuracy: 0.572400\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss:     0.7382 Validation Accuracy: 0.569200\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss:     0.7196 Validation Accuracy: 0.569800\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss:     0.7457 Validation Accuracy: 0.572200\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss:     0.8148 Validation Accuracy: 0.565600\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     0.8849 Validation Accuracy: 0.568000\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss:     0.7575 Validation Accuracy: 0.567400\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss:     0.7132 Validation Accuracy: 0.571000\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss:     0.7669 Validation Accuracy: 0.572600\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss:     0.8135 Validation Accuracy: 0.568000\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     0.8947 Validation Accuracy: 0.573600\n",
      "Epoch 401, CIFAR-10 Batch 2:  Loss:     0.7530 Validation Accuracy: 0.569200\n",
      "Epoch 401, CIFAR-10 Batch 3:  Loss:     0.7270 Validation Accuracy: 0.573600\n",
      "Epoch 401, CIFAR-10 Batch 4:  Loss:     0.7488 Validation Accuracy: 0.575200\n",
      "Epoch 401, CIFAR-10 Batch 5:  Loss:     0.8357 Validation Accuracy: 0.574200\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     0.8830 Validation Accuracy: 0.571000\n",
      "Epoch 402, CIFAR-10 Batch 2:  Loss:     0.7395 Validation Accuracy: 0.572400\n",
      "Epoch 402, CIFAR-10 Batch 3:  Loss:     0.7343 Validation Accuracy: 0.571800\n",
      "Epoch 402, CIFAR-10 Batch 4:  Loss:     0.7666 Validation Accuracy: 0.571400\n",
      "Epoch 402, CIFAR-10 Batch 5:  Loss:     0.8321 Validation Accuracy: 0.575400\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     0.8950 Validation Accuracy: 0.571000\n",
      "Epoch 403, CIFAR-10 Batch 2:  Loss:     0.7497 Validation Accuracy: 0.569800\n",
      "Epoch 403, CIFAR-10 Batch 3:  Loss:     0.7186 Validation Accuracy: 0.573000\n",
      "Epoch 403, CIFAR-10 Batch 4:  Loss:     0.7364 Validation Accuracy: 0.571600\n",
      "Epoch 403, CIFAR-10 Batch 5:  Loss:     0.8346 Validation Accuracy: 0.575000\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     0.8853 Validation Accuracy: 0.566000\n",
      "Epoch 404, CIFAR-10 Batch 2:  Loss:     0.7436 Validation Accuracy: 0.570400\n",
      "Epoch 404, CIFAR-10 Batch 3:  Loss:     0.6927 Validation Accuracy: 0.577200\n",
      "Epoch 404, CIFAR-10 Batch 4:  Loss:     0.7379 Validation Accuracy: 0.573600\n",
      "Epoch 404, CIFAR-10 Batch 5:  Loss:     0.8437 Validation Accuracy: 0.577200\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     0.8823 Validation Accuracy: 0.563800\n",
      "Epoch 405, CIFAR-10 Batch 2:  Loss:     0.7529 Validation Accuracy: 0.565000\n",
      "Epoch 405, CIFAR-10 Batch 3:  Loss:     0.7059 Validation Accuracy: 0.577000\n",
      "Epoch 405, CIFAR-10 Batch 4:  Loss:     0.7480 Validation Accuracy: 0.575000\n",
      "Epoch 405, CIFAR-10 Batch 5:  Loss:     0.8458 Validation Accuracy: 0.570000\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     0.8724 Validation Accuracy: 0.570400\n",
      "Epoch 406, CIFAR-10 Batch 2:  Loss:     0.7639 Validation Accuracy: 0.572400\n",
      "Epoch 406, CIFAR-10 Batch 3:  Loss:     0.7034 Validation Accuracy: 0.570400\n",
      "Epoch 406, CIFAR-10 Batch 4:  Loss:     0.7487 Validation Accuracy: 0.572600\n",
      "Epoch 406, CIFAR-10 Batch 5:  Loss:     0.8298 Validation Accuracy: 0.574400\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     0.8816 Validation Accuracy: 0.569600\n",
      "Epoch 407, CIFAR-10 Batch 2:  Loss:     0.7517 Validation Accuracy: 0.572200\n",
      "Epoch 407, CIFAR-10 Batch 3:  Loss:     0.7284 Validation Accuracy: 0.573600\n",
      "Epoch 407, CIFAR-10 Batch 4:  Loss:     0.7462 Validation Accuracy: 0.572200\n",
      "Epoch 407, CIFAR-10 Batch 5:  Loss:     0.8364 Validation Accuracy: 0.576200\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     0.8926 Validation Accuracy: 0.571800\n",
      "Epoch 408, CIFAR-10 Batch 2:  Loss:     0.7691 Validation Accuracy: 0.573400\n",
      "Epoch 408, CIFAR-10 Batch 3:  Loss:     0.7366 Validation Accuracy: 0.569000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408, CIFAR-10 Batch 4:  Loss:     0.7477 Validation Accuracy: 0.574000\n",
      "Epoch 408, CIFAR-10 Batch 5:  Loss:     0.8418 Validation Accuracy: 0.569800\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     0.8831 Validation Accuracy: 0.569800\n",
      "Epoch 409, CIFAR-10 Batch 2:  Loss:     0.7680 Validation Accuracy: 0.572600\n",
      "Epoch 409, CIFAR-10 Batch 3:  Loss:     0.7105 Validation Accuracy: 0.575000\n",
      "Epoch 409, CIFAR-10 Batch 4:  Loss:     0.7406 Validation Accuracy: 0.571000\n",
      "Epoch 409, CIFAR-10 Batch 5:  Loss:     0.8474 Validation Accuracy: 0.572800\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     0.8699 Validation Accuracy: 0.572000\n",
      "Epoch 410, CIFAR-10 Batch 2:  Loss:     0.7644 Validation Accuracy: 0.571200\n",
      "Epoch 410, CIFAR-10 Batch 3:  Loss:     0.7335 Validation Accuracy: 0.567400\n",
      "Epoch 410, CIFAR-10 Batch 4:  Loss:     0.7375 Validation Accuracy: 0.570800\n",
      "Epoch 410, CIFAR-10 Batch 5:  Loss:     0.8340 Validation Accuracy: 0.576000\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     0.8754 Validation Accuracy: 0.570800\n",
      "Epoch 411, CIFAR-10 Batch 2:  Loss:     0.7540 Validation Accuracy: 0.572000\n",
      "Epoch 411, CIFAR-10 Batch 3:  Loss:     0.7264 Validation Accuracy: 0.568000\n",
      "Epoch 411, CIFAR-10 Batch 4:  Loss:     0.7343 Validation Accuracy: 0.573200\n",
      "Epoch 411, CIFAR-10 Batch 5:  Loss:     0.8218 Validation Accuracy: 0.573000\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     0.8727 Validation Accuracy: 0.570200\n",
      "Epoch 412, CIFAR-10 Batch 2:  Loss:     0.7445 Validation Accuracy: 0.569600\n",
      "Epoch 412, CIFAR-10 Batch 3:  Loss:     0.7080 Validation Accuracy: 0.568800\n",
      "Epoch 412, CIFAR-10 Batch 4:  Loss:     0.7251 Validation Accuracy: 0.576000\n",
      "Epoch 412, CIFAR-10 Batch 5:  Loss:     0.8406 Validation Accuracy: 0.572000\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     0.8832 Validation Accuracy: 0.572200\n",
      "Epoch 413, CIFAR-10 Batch 2:  Loss:     0.7484 Validation Accuracy: 0.573200\n",
      "Epoch 413, CIFAR-10 Batch 3:  Loss:     0.7373 Validation Accuracy: 0.570400\n",
      "Epoch 413, CIFAR-10 Batch 4:  Loss:     0.7376 Validation Accuracy: 0.576000\n",
      "Epoch 413, CIFAR-10 Batch 5:  Loss:     0.8275 Validation Accuracy: 0.577200\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     0.8885 Validation Accuracy: 0.573000\n",
      "Epoch 414, CIFAR-10 Batch 2:  Loss:     0.7400 Validation Accuracy: 0.572400\n",
      "Epoch 414, CIFAR-10 Batch 3:  Loss:     0.7231 Validation Accuracy: 0.573200\n",
      "Epoch 414, CIFAR-10 Batch 4:  Loss:     0.7333 Validation Accuracy: 0.575600\n",
      "Epoch 414, CIFAR-10 Batch 5:  Loss:     0.8353 Validation Accuracy: 0.572200\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     0.9057 Validation Accuracy: 0.566000\n",
      "Epoch 415, CIFAR-10 Batch 2:  Loss:     0.7393 Validation Accuracy: 0.571600\n",
      "Epoch 415, CIFAR-10 Batch 3:  Loss:     0.7145 Validation Accuracy: 0.574400\n",
      "Epoch 415, CIFAR-10 Batch 4:  Loss:     0.7264 Validation Accuracy: 0.574200\n",
      "Epoch 415, CIFAR-10 Batch 5:  Loss:     0.8307 Validation Accuracy: 0.575000\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     0.8875 Validation Accuracy: 0.570000\n",
      "Epoch 416, CIFAR-10 Batch 2:  Loss:     0.7419 Validation Accuracy: 0.571400\n",
      "Epoch 416, CIFAR-10 Batch 3:  Loss:     0.7486 Validation Accuracy: 0.567000\n",
      "Epoch 416, CIFAR-10 Batch 4:  Loss:     0.7311 Validation Accuracy: 0.570000\n",
      "Epoch 416, CIFAR-10 Batch 5:  Loss:     0.8106 Validation Accuracy: 0.573600\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     0.8943 Validation Accuracy: 0.571800\n",
      "Epoch 417, CIFAR-10 Batch 2:  Loss:     0.7307 Validation Accuracy: 0.570000\n",
      "Epoch 417, CIFAR-10 Batch 3:  Loss:     0.7193 Validation Accuracy: 0.576800\n",
      "Epoch 417, CIFAR-10 Batch 4:  Loss:     0.7458 Validation Accuracy: 0.570400\n",
      "Epoch 417, CIFAR-10 Batch 5:  Loss:     0.8185 Validation Accuracy: 0.572600\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     0.8836 Validation Accuracy: 0.569000\n",
      "Epoch 418, CIFAR-10 Batch 2:  Loss:     0.7345 Validation Accuracy: 0.572200\n",
      "Epoch 418, CIFAR-10 Batch 3:  Loss:     0.7167 Validation Accuracy: 0.571400\n",
      "Epoch 418, CIFAR-10 Batch 4:  Loss:     0.7330 Validation Accuracy: 0.574200\n",
      "Epoch 418, CIFAR-10 Batch 5:  Loss:     0.8474 Validation Accuracy: 0.573600\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     0.8799 Validation Accuracy: 0.569600\n",
      "Epoch 419, CIFAR-10 Batch 2:  Loss:     0.7060 Validation Accuracy: 0.573600\n",
      "Epoch 419, CIFAR-10 Batch 3:  Loss:     0.7199 Validation Accuracy: 0.575200\n",
      "Epoch 419, CIFAR-10 Batch 4:  Loss:     0.7236 Validation Accuracy: 0.577200\n",
      "Epoch 419, CIFAR-10 Batch 5:  Loss:     0.8570 Validation Accuracy: 0.574000\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     0.8781 Validation Accuracy: 0.570600\n",
      "Epoch 420, CIFAR-10 Batch 2:  Loss:     0.7290 Validation Accuracy: 0.569400\n",
      "Epoch 420, CIFAR-10 Batch 3:  Loss:     0.7025 Validation Accuracy: 0.576000\n",
      "Epoch 420, CIFAR-10 Batch 4:  Loss:     0.7275 Validation Accuracy: 0.574400\n",
      "Epoch 420, CIFAR-10 Batch 5:  Loss:     0.8428 Validation Accuracy: 0.574600\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     0.8892 Validation Accuracy: 0.575400\n",
      "Epoch 421, CIFAR-10 Batch 2:  Loss:     0.7391 Validation Accuracy: 0.576600\n",
      "Epoch 421, CIFAR-10 Batch 3:  Loss:     0.7041 Validation Accuracy: 0.575600\n",
      "Epoch 421, CIFAR-10 Batch 4:  Loss:     0.7186 Validation Accuracy: 0.576800\n",
      "Epoch 421, CIFAR-10 Batch 5:  Loss:     0.8469 Validation Accuracy: 0.567400\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     0.8859 Validation Accuracy: 0.567200\n",
      "Epoch 422, CIFAR-10 Batch 2:  Loss:     0.7311 Validation Accuracy: 0.569400\n",
      "Epoch 422, CIFAR-10 Batch 3:  Loss:     0.7837 Validation Accuracy: 0.566600\n",
      "Epoch 422, CIFAR-10 Batch 4:  Loss:     0.7270 Validation Accuracy: 0.575200\n",
      "Epoch 422, CIFAR-10 Batch 5:  Loss:     0.8138 Validation Accuracy: 0.572000\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     0.8647 Validation Accuracy: 0.563800\n",
      "Epoch 423, CIFAR-10 Batch 2:  Loss:     0.7427 Validation Accuracy: 0.578400\n",
      "Epoch 423, CIFAR-10 Batch 3:  Loss:     0.7135 Validation Accuracy: 0.573800\n",
      "Epoch 423, CIFAR-10 Batch 4:  Loss:     0.7383 Validation Accuracy: 0.574200\n",
      "Epoch 423, CIFAR-10 Batch 5:  Loss:     0.8521 Validation Accuracy: 0.576600\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     0.8875 Validation Accuracy: 0.567400\n",
      "Epoch 424, CIFAR-10 Batch 2:  Loss:     0.7361 Validation Accuracy: 0.572400\n",
      "Epoch 424, CIFAR-10 Batch 3:  Loss:     0.7387 Validation Accuracy: 0.570800\n",
      "Epoch 424, CIFAR-10 Batch 4:  Loss:     0.7278 Validation Accuracy: 0.572200\n",
      "Epoch 424, CIFAR-10 Batch 5:  Loss:     0.8561 Validation Accuracy: 0.578200\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     0.8761 Validation Accuracy: 0.568800\n",
      "Epoch 425, CIFAR-10 Batch 2:  Loss:     0.7299 Validation Accuracy: 0.574000\n",
      "Epoch 425, CIFAR-10 Batch 3:  Loss:     0.7307 Validation Accuracy: 0.572000\n",
      "Epoch 425, CIFAR-10 Batch 4:  Loss:     0.7246 Validation Accuracy: 0.571200\n",
      "Epoch 425, CIFAR-10 Batch 5:  Loss:     0.8271 Validation Accuracy: 0.575000\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     0.8627 Validation Accuracy: 0.566600\n",
      "Epoch 426, CIFAR-10 Batch 2:  Loss:     0.7082 Validation Accuracy: 0.568000\n",
      "Epoch 426, CIFAR-10 Batch 3:  Loss:     0.7070 Validation Accuracy: 0.576200\n",
      "Epoch 426, CIFAR-10 Batch 4:  Loss:     0.7527 Validation Accuracy: 0.575600\n",
      "Epoch 426, CIFAR-10 Batch 5:  Loss:     0.8242 Validation Accuracy: 0.577200\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     0.8635 Validation Accuracy: 0.569200\n",
      "Epoch 427, CIFAR-10 Batch 2:  Loss:     0.7277 Validation Accuracy: 0.568000\n",
      "Epoch 427, CIFAR-10 Batch 3:  Loss:     0.6996 Validation Accuracy: 0.575800\n",
      "Epoch 427, CIFAR-10 Batch 4:  Loss:     0.7446 Validation Accuracy: 0.575000\n",
      "Epoch 427, CIFAR-10 Batch 5:  Loss:     0.8529 Validation Accuracy: 0.575800\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     0.8883 Validation Accuracy: 0.573000\n",
      "Epoch 428, CIFAR-10 Batch 2:  Loss:     0.7377 Validation Accuracy: 0.574200\n",
      "Epoch 428, CIFAR-10 Batch 3:  Loss:     0.7287 Validation Accuracy: 0.575600\n",
      "Epoch 428, CIFAR-10 Batch 4:  Loss:     0.7377 Validation Accuracy: 0.571800\n",
      "Epoch 428, CIFAR-10 Batch 5:  Loss:     0.8188 Validation Accuracy: 0.579000\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     0.8688 Validation Accuracy: 0.571800\n",
      "Epoch 429, CIFAR-10 Batch 2:  Loss:     0.7300 Validation Accuracy: 0.574400\n",
      "Epoch 429, CIFAR-10 Batch 3:  Loss:     0.7158 Validation Accuracy: 0.574000\n",
      "Epoch 429, CIFAR-10 Batch 4:  Loss:     0.7484 Validation Accuracy: 0.576600\n",
      "Epoch 429, CIFAR-10 Batch 5:  Loss:     0.8267 Validation Accuracy: 0.579400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     0.8795 Validation Accuracy: 0.573000\n",
      "Epoch 430, CIFAR-10 Batch 2:  Loss:     0.7284 Validation Accuracy: 0.575000\n",
      "Epoch 430, CIFAR-10 Batch 3:  Loss:     0.7424 Validation Accuracy: 0.577400\n",
      "Epoch 430, CIFAR-10 Batch 4:  Loss:     0.7621 Validation Accuracy: 0.572200\n",
      "Epoch 430, CIFAR-10 Batch 5:  Loss:     0.8336 Validation Accuracy: 0.578200\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     0.8813 Validation Accuracy: 0.565800\n",
      "Epoch 431, CIFAR-10 Batch 2:  Loss:     0.7330 Validation Accuracy: 0.568800\n",
      "Epoch 431, CIFAR-10 Batch 3:  Loss:     0.6950 Validation Accuracy: 0.578400\n",
      "Epoch 431, CIFAR-10 Batch 4:  Loss:     0.7326 Validation Accuracy: 0.574800\n",
      "Epoch 431, CIFAR-10 Batch 5:  Loss:     0.8318 Validation Accuracy: 0.578000\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     0.8695 Validation Accuracy: 0.574800\n",
      "Epoch 432, CIFAR-10 Batch 2:  Loss:     0.7475 Validation Accuracy: 0.572600\n",
      "Epoch 432, CIFAR-10 Batch 3:  Loss:     0.7333 Validation Accuracy: 0.570600\n",
      "Epoch 432, CIFAR-10 Batch 4:  Loss:     0.7267 Validation Accuracy: 0.574400\n",
      "Epoch 432, CIFAR-10 Batch 5:  Loss:     0.8432 Validation Accuracy: 0.579200\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     0.9520 Validation Accuracy: 0.556000\n",
      "Epoch 433, CIFAR-10 Batch 2:  Loss:     0.7387 Validation Accuracy: 0.570800\n",
      "Epoch 433, CIFAR-10 Batch 3:  Loss:     0.7120 Validation Accuracy: 0.575000\n",
      "Epoch 433, CIFAR-10 Batch 4:  Loss:     0.7524 Validation Accuracy: 0.574200\n",
      "Epoch 433, CIFAR-10 Batch 5:  Loss:     0.8385 Validation Accuracy: 0.572400\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     0.8809 Validation Accuracy: 0.570000\n",
      "Epoch 434, CIFAR-10 Batch 2:  Loss:     0.7288 Validation Accuracy: 0.568800\n",
      "Epoch 434, CIFAR-10 Batch 3:  Loss:     0.7328 Validation Accuracy: 0.570800\n",
      "Epoch 434, CIFAR-10 Batch 4:  Loss:     0.7488 Validation Accuracy: 0.567000\n",
      "Epoch 434, CIFAR-10 Batch 5:  Loss:     0.8152 Validation Accuracy: 0.576000\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     0.8587 Validation Accuracy: 0.570000\n",
      "Epoch 435, CIFAR-10 Batch 2:  Loss:     0.7421 Validation Accuracy: 0.574800\n",
      "Epoch 435, CIFAR-10 Batch 3:  Loss:     0.7032 Validation Accuracy: 0.576800\n",
      "Epoch 435, CIFAR-10 Batch 4:  Loss:     0.7212 Validation Accuracy: 0.572600\n",
      "Epoch 435, CIFAR-10 Batch 5:  Loss:     0.8147 Validation Accuracy: 0.577200\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     0.8745 Validation Accuracy: 0.565400\n",
      "Epoch 436, CIFAR-10 Batch 2:  Loss:     0.7397 Validation Accuracy: 0.571000\n",
      "Epoch 436, CIFAR-10 Batch 3:  Loss:     0.7267 Validation Accuracy: 0.574200\n",
      "Epoch 436, CIFAR-10 Batch 4:  Loss:     0.7323 Validation Accuracy: 0.571600\n",
      "Epoch 436, CIFAR-10 Batch 5:  Loss:     0.8666 Validation Accuracy: 0.574600\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     0.8651 Validation Accuracy: 0.568200\n",
      "Epoch 437, CIFAR-10 Batch 2:  Loss:     0.7228 Validation Accuracy: 0.573400\n",
      "Epoch 437, CIFAR-10 Batch 3:  Loss:     0.7031 Validation Accuracy: 0.577000\n",
      "Epoch 437, CIFAR-10 Batch 4:  Loss:     0.7412 Validation Accuracy: 0.570200\n",
      "Epoch 437, CIFAR-10 Batch 5:  Loss:     0.8485 Validation Accuracy: 0.573800\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     0.8700 Validation Accuracy: 0.570800\n",
      "Epoch 438, CIFAR-10 Batch 2:  Loss:     0.7361 Validation Accuracy: 0.571000\n",
      "Epoch 438, CIFAR-10 Batch 3:  Loss:     0.6821 Validation Accuracy: 0.571800\n",
      "Epoch 438, CIFAR-10 Batch 4:  Loss:     0.7415 Validation Accuracy: 0.569600\n",
      "Epoch 438, CIFAR-10 Batch 5:  Loss:     0.8322 Validation Accuracy: 0.574800\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     0.8662 Validation Accuracy: 0.567600\n",
      "Epoch 439, CIFAR-10 Batch 2:  Loss:     0.7303 Validation Accuracy: 0.573000\n",
      "Epoch 439, CIFAR-10 Batch 3:  Loss:     0.7316 Validation Accuracy: 0.576400\n",
      "Epoch 439, CIFAR-10 Batch 4:  Loss:     0.7350 Validation Accuracy: 0.574000\n",
      "Epoch 439, CIFAR-10 Batch 5:  Loss:     0.8290 Validation Accuracy: 0.574800\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     0.8628 Validation Accuracy: 0.571600\n",
      "Epoch 440, CIFAR-10 Batch 2:  Loss:     0.7257 Validation Accuracy: 0.573400\n",
      "Epoch 440, CIFAR-10 Batch 3:  Loss:     0.6947 Validation Accuracy: 0.574200\n",
      "Epoch 440, CIFAR-10 Batch 4:  Loss:     0.7160 Validation Accuracy: 0.576000\n",
      "Epoch 440, CIFAR-10 Batch 5:  Loss:     0.8351 Validation Accuracy: 0.577400\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     0.8612 Validation Accuracy: 0.568000\n",
      "Epoch 441, CIFAR-10 Batch 2:  Loss:     0.7374 Validation Accuracy: 0.572600\n",
      "Epoch 441, CIFAR-10 Batch 3:  Loss:     0.7200 Validation Accuracy: 0.575600\n",
      "Epoch 441, CIFAR-10 Batch 4:  Loss:     0.7329 Validation Accuracy: 0.576600\n",
      "Epoch 441, CIFAR-10 Batch 5:  Loss:     0.8119 Validation Accuracy: 0.578400\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     0.8609 Validation Accuracy: 0.569800\n",
      "Epoch 442, CIFAR-10 Batch 2:  Loss:     0.7348 Validation Accuracy: 0.571200\n",
      "Epoch 442, CIFAR-10 Batch 3:  Loss:     0.6949 Validation Accuracy: 0.576800\n",
      "Epoch 442, CIFAR-10 Batch 4:  Loss:     0.7285 Validation Accuracy: 0.575000\n",
      "Epoch 442, CIFAR-10 Batch 5:  Loss:     0.8512 Validation Accuracy: 0.576600\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     0.8779 Validation Accuracy: 0.571000\n",
      "Epoch 443, CIFAR-10 Batch 2:  Loss:     0.7300 Validation Accuracy: 0.572400\n",
      "Epoch 443, CIFAR-10 Batch 3:  Loss:     0.6911 Validation Accuracy: 0.574400\n",
      "Epoch 443, CIFAR-10 Batch 4:  Loss:     0.7166 Validation Accuracy: 0.572200\n",
      "Epoch 443, CIFAR-10 Batch 5:  Loss:     0.8288 Validation Accuracy: 0.576800\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     0.8552 Validation Accuracy: 0.573000\n",
      "Epoch 444, CIFAR-10 Batch 2:  Loss:     0.7348 Validation Accuracy: 0.571800\n",
      "Epoch 444, CIFAR-10 Batch 3:  Loss:     0.6922 Validation Accuracy: 0.573800\n",
      "Epoch 444, CIFAR-10 Batch 4:  Loss:     0.7278 Validation Accuracy: 0.572600\n",
      "Epoch 444, CIFAR-10 Batch 5:  Loss:     0.8028 Validation Accuracy: 0.572800\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     0.8870 Validation Accuracy: 0.570200\n",
      "Epoch 445, CIFAR-10 Batch 2:  Loss:     0.7251 Validation Accuracy: 0.564800\n",
      "Epoch 445, CIFAR-10 Batch 3:  Loss:     0.6833 Validation Accuracy: 0.576200\n",
      "Epoch 445, CIFAR-10 Batch 4:  Loss:     0.7287 Validation Accuracy: 0.570400\n",
      "Epoch 445, CIFAR-10 Batch 5:  Loss:     0.7933 Validation Accuracy: 0.575600\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     0.8568 Validation Accuracy: 0.570200\n",
      "Epoch 446, CIFAR-10 Batch 2:  Loss:     0.7042 Validation Accuracy: 0.572200\n",
      "Epoch 446, CIFAR-10 Batch 3:  Loss:     0.6848 Validation Accuracy: 0.574200\n",
      "Epoch 446, CIFAR-10 Batch 4:  Loss:     0.7088 Validation Accuracy: 0.569000\n",
      "Epoch 446, CIFAR-10 Batch 5:  Loss:     0.7903 Validation Accuracy: 0.574600\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     0.8795 Validation Accuracy: 0.572000\n",
      "Epoch 447, CIFAR-10 Batch 2:  Loss:     0.7064 Validation Accuracy: 0.571400\n",
      "Epoch 447, CIFAR-10 Batch 3:  Loss:     0.6646 Validation Accuracy: 0.572600\n",
      "Epoch 447, CIFAR-10 Batch 4:  Loss:     0.7147 Validation Accuracy: 0.571800\n",
      "Epoch 447, CIFAR-10 Batch 5:  Loss:     0.8206 Validation Accuracy: 0.575800\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     0.8859 Validation Accuracy: 0.564800\n",
      "Epoch 448, CIFAR-10 Batch 2:  Loss:     0.7223 Validation Accuracy: 0.573800\n",
      "Epoch 448, CIFAR-10 Batch 3:  Loss:     0.6833 Validation Accuracy: 0.573600\n",
      "Epoch 448, CIFAR-10 Batch 4:  Loss:     0.7220 Validation Accuracy: 0.570000\n",
      "Epoch 448, CIFAR-10 Batch 5:  Loss:     0.8213 Validation Accuracy: 0.567600\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     0.8842 Validation Accuracy: 0.568600\n",
      "Epoch 449, CIFAR-10 Batch 2:  Loss:     0.7343 Validation Accuracy: 0.571000\n",
      "Epoch 449, CIFAR-10 Batch 3:  Loss:     0.6764 Validation Accuracy: 0.573200\n",
      "Epoch 449, CIFAR-10 Batch 4:  Loss:     0.7163 Validation Accuracy: 0.571600\n",
      "Epoch 449, CIFAR-10 Batch 5:  Loss:     0.7994 Validation Accuracy: 0.570200\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     0.8608 Validation Accuracy: 0.566600\n",
      "Epoch 450, CIFAR-10 Batch 2:  Loss:     0.7313 Validation Accuracy: 0.567800\n",
      "Epoch 450, CIFAR-10 Batch 3:  Loss:     0.7031 Validation Accuracy: 0.574800\n",
      "Epoch 450, CIFAR-10 Batch 4:  Loss:     0.7165 Validation Accuracy: 0.572000\n",
      "Epoch 450, CIFAR-10 Batch 5:  Loss:     0.8140 Validation Accuracy: 0.573600\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     0.8633 Validation Accuracy: 0.571200\n",
      "Epoch 451, CIFAR-10 Batch 2:  Loss:     0.7207 Validation Accuracy: 0.575400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451, CIFAR-10 Batch 3:  Loss:     0.6804 Validation Accuracy: 0.573200\n",
      "Epoch 451, CIFAR-10 Batch 4:  Loss:     0.7209 Validation Accuracy: 0.572200\n",
      "Epoch 451, CIFAR-10 Batch 5:  Loss:     0.8514 Validation Accuracy: 0.573800\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     0.8791 Validation Accuracy: 0.572200\n",
      "Epoch 452, CIFAR-10 Batch 2:  Loss:     0.7350 Validation Accuracy: 0.574200\n",
      "Epoch 452, CIFAR-10 Batch 3:  Loss:     0.6880 Validation Accuracy: 0.575200\n",
      "Epoch 452, CIFAR-10 Batch 4:  Loss:     0.6953 Validation Accuracy: 0.574600\n",
      "Epoch 452, CIFAR-10 Batch 5:  Loss:     0.8292 Validation Accuracy: 0.575200\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     0.8690 Validation Accuracy: 0.578200\n",
      "Epoch 453, CIFAR-10 Batch 2:  Loss:     0.7341 Validation Accuracy: 0.572600\n",
      "Epoch 453, CIFAR-10 Batch 3:  Loss:     0.6988 Validation Accuracy: 0.575800\n",
      "Epoch 453, CIFAR-10 Batch 4:  Loss:     0.7192 Validation Accuracy: 0.570800\n",
      "Epoch 453, CIFAR-10 Batch 5:  Loss:     0.8439 Validation Accuracy: 0.572400\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     0.8779 Validation Accuracy: 0.572000\n",
      "Epoch 454, CIFAR-10 Batch 2:  Loss:     0.7001 Validation Accuracy: 0.574400\n",
      "Epoch 454, CIFAR-10 Batch 3:  Loss:     0.7074 Validation Accuracy: 0.572600\n",
      "Epoch 454, CIFAR-10 Batch 4:  Loss:     0.7159 Validation Accuracy: 0.575400\n",
      "Epoch 454, CIFAR-10 Batch 5:  Loss:     0.8173 Validation Accuracy: 0.578000\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     0.8860 Validation Accuracy: 0.569600\n",
      "Epoch 455, CIFAR-10 Batch 2:  Loss:     0.7153 Validation Accuracy: 0.573000\n",
      "Epoch 455, CIFAR-10 Batch 3:  Loss:     0.7022 Validation Accuracy: 0.574000\n",
      "Epoch 455, CIFAR-10 Batch 4:  Loss:     0.7106 Validation Accuracy: 0.577400\n",
      "Epoch 455, CIFAR-10 Batch 5:  Loss:     0.8235 Validation Accuracy: 0.574600\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     0.8732 Validation Accuracy: 0.570000\n",
      "Epoch 456, CIFAR-10 Batch 2:  Loss:     0.7266 Validation Accuracy: 0.570400\n",
      "Epoch 456, CIFAR-10 Batch 3:  Loss:     0.6658 Validation Accuracy: 0.576000\n",
      "Epoch 456, CIFAR-10 Batch 4:  Loss:     0.7043 Validation Accuracy: 0.572400\n",
      "Epoch 456, CIFAR-10 Batch 5:  Loss:     0.8337 Validation Accuracy: 0.574800\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     0.8909 Validation Accuracy: 0.568400\n",
      "Epoch 457, CIFAR-10 Batch 2:  Loss:     0.7372 Validation Accuracy: 0.571400\n",
      "Epoch 457, CIFAR-10 Batch 3:  Loss:     0.6987 Validation Accuracy: 0.577000\n",
      "Epoch 457, CIFAR-10 Batch 4:  Loss:     0.7381 Validation Accuracy: 0.571600\n",
      "Epoch 457, CIFAR-10 Batch 5:  Loss:     0.8138 Validation Accuracy: 0.580400\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     0.8847 Validation Accuracy: 0.572800\n",
      "Epoch 458, CIFAR-10 Batch 2:  Loss:     0.7231 Validation Accuracy: 0.575400\n",
      "Epoch 458, CIFAR-10 Batch 3:  Loss:     0.6929 Validation Accuracy: 0.574000\n",
      "Epoch 458, CIFAR-10 Batch 4:  Loss:     0.7267 Validation Accuracy: 0.576600\n",
      "Epoch 458, CIFAR-10 Batch 5:  Loss:     0.8247 Validation Accuracy: 0.577400\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     0.9027 Validation Accuracy: 0.571800\n",
      "Epoch 459, CIFAR-10 Batch 2:  Loss:     0.7141 Validation Accuracy: 0.571200\n",
      "Epoch 459, CIFAR-10 Batch 3:  Loss:     0.7085 Validation Accuracy: 0.577400\n",
      "Epoch 459, CIFAR-10 Batch 4:  Loss:     0.7044 Validation Accuracy: 0.577600\n",
      "Epoch 459, CIFAR-10 Batch 5:  Loss:     0.8099 Validation Accuracy: 0.571200\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     0.9008 Validation Accuracy: 0.565800\n",
      "Epoch 460, CIFAR-10 Batch 2:  Loss:     0.7218 Validation Accuracy: 0.577000\n",
      "Epoch 460, CIFAR-10 Batch 3:  Loss:     0.6717 Validation Accuracy: 0.576600\n",
      "Epoch 460, CIFAR-10 Batch 4:  Loss:     0.7003 Validation Accuracy: 0.572800\n",
      "Epoch 460, CIFAR-10 Batch 5:  Loss:     0.8228 Validation Accuracy: 0.578400\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     0.8718 Validation Accuracy: 0.570000\n",
      "Epoch 461, CIFAR-10 Batch 2:  Loss:     0.7190 Validation Accuracy: 0.574800\n",
      "Epoch 461, CIFAR-10 Batch 3:  Loss:     0.6757 Validation Accuracy: 0.574200\n",
      "Epoch 461, CIFAR-10 Batch 4:  Loss:     0.7053 Validation Accuracy: 0.577200\n",
      "Epoch 461, CIFAR-10 Batch 5:  Loss:     0.8114 Validation Accuracy: 0.575600\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     0.8684 Validation Accuracy: 0.574800\n",
      "Epoch 462, CIFAR-10 Batch 2:  Loss:     0.7216 Validation Accuracy: 0.576600\n",
      "Epoch 462, CIFAR-10 Batch 3:  Loss:     0.6881 Validation Accuracy: 0.572400\n",
      "Epoch 462, CIFAR-10 Batch 4:  Loss:     0.7059 Validation Accuracy: 0.578200\n",
      "Epoch 462, CIFAR-10 Batch 5:  Loss:     0.8150 Validation Accuracy: 0.574800\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     0.8719 Validation Accuracy: 0.573400\n",
      "Epoch 463, CIFAR-10 Batch 2:  Loss:     0.7141 Validation Accuracy: 0.573400\n",
      "Epoch 463, CIFAR-10 Batch 3:  Loss:     0.6853 Validation Accuracy: 0.578000\n",
      "Epoch 463, CIFAR-10 Batch 4:  Loss:     0.7061 Validation Accuracy: 0.576400\n",
      "Epoch 463, CIFAR-10 Batch 5:  Loss:     0.8247 Validation Accuracy: 0.575800\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     0.8850 Validation Accuracy: 0.570000\n",
      "Epoch 464, CIFAR-10 Batch 2:  Loss:     0.7288 Validation Accuracy: 0.571400\n",
      "Epoch 464, CIFAR-10 Batch 3:  Loss:     0.7125 Validation Accuracy: 0.578600\n",
      "Epoch 464, CIFAR-10 Batch 4:  Loss:     0.7185 Validation Accuracy: 0.573400\n",
      "Epoch 464, CIFAR-10 Batch 5:  Loss:     0.8219 Validation Accuracy: 0.577000\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     0.8982 Validation Accuracy: 0.567000\n",
      "Epoch 465, CIFAR-10 Batch 2:  Loss:     0.7189 Validation Accuracy: 0.573200\n",
      "Epoch 465, CIFAR-10 Batch 3:  Loss:     0.6765 Validation Accuracy: 0.578600\n",
      "Epoch 465, CIFAR-10 Batch 4:  Loss:     0.7195 Validation Accuracy: 0.579000\n",
      "Epoch 465, CIFAR-10 Batch 5:  Loss:     0.8220 Validation Accuracy: 0.574600\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     0.8916 Validation Accuracy: 0.567000\n",
      "Epoch 466, CIFAR-10 Batch 2:  Loss:     0.7266 Validation Accuracy: 0.574200\n",
      "Epoch 466, CIFAR-10 Batch 3:  Loss:     0.6836 Validation Accuracy: 0.578600\n",
      "Epoch 466, CIFAR-10 Batch 4:  Loss:     0.7294 Validation Accuracy: 0.574600\n",
      "Epoch 466, CIFAR-10 Batch 5:  Loss:     0.8061 Validation Accuracy: 0.577600\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     0.8811 Validation Accuracy: 0.566800\n",
      "Epoch 467, CIFAR-10 Batch 2:  Loss:     0.7267 Validation Accuracy: 0.568600\n",
      "Epoch 467, CIFAR-10 Batch 3:  Loss:     0.6917 Validation Accuracy: 0.574000\n",
      "Epoch 467, CIFAR-10 Batch 4:  Loss:     0.7111 Validation Accuracy: 0.573400\n",
      "Epoch 467, CIFAR-10 Batch 5:  Loss:     0.8032 Validation Accuracy: 0.573000\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     0.8785 Validation Accuracy: 0.568000\n",
      "Epoch 468, CIFAR-10 Batch 2:  Loss:     0.7414 Validation Accuracy: 0.572600\n",
      "Epoch 468, CIFAR-10 Batch 3:  Loss:     0.7089 Validation Accuracy: 0.576600\n",
      "Epoch 468, CIFAR-10 Batch 4:  Loss:     0.7143 Validation Accuracy: 0.573600\n",
      "Epoch 468, CIFAR-10 Batch 5:  Loss:     0.8191 Validation Accuracy: 0.577800\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     0.8991 Validation Accuracy: 0.571000\n",
      "Epoch 469, CIFAR-10 Batch 2:  Loss:     0.7330 Validation Accuracy: 0.574200\n",
      "Epoch 469, CIFAR-10 Batch 3:  Loss:     0.7331 Validation Accuracy: 0.576600\n",
      "Epoch 469, CIFAR-10 Batch 4:  Loss:     0.7279 Validation Accuracy: 0.576800\n",
      "Epoch 469, CIFAR-10 Batch 5:  Loss:     0.8049 Validation Accuracy: 0.578000\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     0.8805 Validation Accuracy: 0.569600\n",
      "Epoch 470, CIFAR-10 Batch 2:  Loss:     0.7147 Validation Accuracy: 0.570000\n",
      "Epoch 470, CIFAR-10 Batch 3:  Loss:     0.7098 Validation Accuracy: 0.575200\n",
      "Epoch 470, CIFAR-10 Batch 4:  Loss:     0.7265 Validation Accuracy: 0.573800\n",
      "Epoch 470, CIFAR-10 Batch 5:  Loss:     0.8448 Validation Accuracy: 0.571600\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     0.8845 Validation Accuracy: 0.563600\n",
      "Epoch 471, CIFAR-10 Batch 2:  Loss:     0.7129 Validation Accuracy: 0.575000\n",
      "Epoch 471, CIFAR-10 Batch 3:  Loss:     0.7042 Validation Accuracy: 0.571800\n",
      "Epoch 471, CIFAR-10 Batch 4:  Loss:     0.7411 Validation Accuracy: 0.571200\n",
      "Epoch 471, CIFAR-10 Batch 5:  Loss:     0.8200 Validation Accuracy: 0.578600\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     0.8787 Validation Accuracy: 0.569400\n",
      "Epoch 472, CIFAR-10 Batch 2:  Loss:     0.7240 Validation Accuracy: 0.575600\n",
      "Epoch 472, CIFAR-10 Batch 3:  Loss:     0.6885 Validation Accuracy: 0.576000\n",
      "Epoch 472, CIFAR-10 Batch 4:  Loss:     0.7209 Validation Accuracy: 0.572400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472, CIFAR-10 Batch 5:  Loss:     0.8037 Validation Accuracy: 0.572000\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     0.9127 Validation Accuracy: 0.566000\n",
      "Epoch 473, CIFAR-10 Batch 2:  Loss:     0.7152 Validation Accuracy: 0.573000\n",
      "Epoch 473, CIFAR-10 Batch 3:  Loss:     0.7111 Validation Accuracy: 0.575800\n",
      "Epoch 473, CIFAR-10 Batch 4:  Loss:     0.7209 Validation Accuracy: 0.577400\n",
      "Epoch 473, CIFAR-10 Batch 5:  Loss:     0.8072 Validation Accuracy: 0.574600\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     0.8899 Validation Accuracy: 0.567600\n",
      "Epoch 474, CIFAR-10 Batch 2:  Loss:     0.7199 Validation Accuracy: 0.569600\n",
      "Epoch 474, CIFAR-10 Batch 3:  Loss:     0.6906 Validation Accuracy: 0.575200\n",
      "Epoch 474, CIFAR-10 Batch 4:  Loss:     0.7160 Validation Accuracy: 0.574600\n",
      "Epoch 474, CIFAR-10 Batch 5:  Loss:     0.8448 Validation Accuracy: 0.572200\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     0.8823 Validation Accuracy: 0.573800\n",
      "Epoch 475, CIFAR-10 Batch 2:  Loss:     0.7155 Validation Accuracy: 0.570200\n",
      "Epoch 475, CIFAR-10 Batch 3:  Loss:     0.7042 Validation Accuracy: 0.576200\n",
      "Epoch 475, CIFAR-10 Batch 4:  Loss:     0.7174 Validation Accuracy: 0.573200\n",
      "Epoch 475, CIFAR-10 Batch 5:  Loss:     0.8183 Validation Accuracy: 0.575000\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     0.8762 Validation Accuracy: 0.573800\n",
      "Epoch 476, CIFAR-10 Batch 2:  Loss:     0.7056 Validation Accuracy: 0.572200\n",
      "Epoch 476, CIFAR-10 Batch 3:  Loss:     0.6835 Validation Accuracy: 0.577200\n",
      "Epoch 476, CIFAR-10 Batch 4:  Loss:     0.7147 Validation Accuracy: 0.574400\n",
      "Epoch 476, CIFAR-10 Batch 5:  Loss:     0.7775 Validation Accuracy: 0.572600\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     0.8700 Validation Accuracy: 0.574200\n",
      "Epoch 477, CIFAR-10 Batch 2:  Loss:     0.7145 Validation Accuracy: 0.566400\n",
      "Epoch 477, CIFAR-10 Batch 3:  Loss:     0.7026 Validation Accuracy: 0.575600\n",
      "Epoch 477, CIFAR-10 Batch 4:  Loss:     0.7098 Validation Accuracy: 0.573000\n",
      "Epoch 477, CIFAR-10 Batch 5:  Loss:     0.8226 Validation Accuracy: 0.573200\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     0.8680 Validation Accuracy: 0.566800\n",
      "Epoch 478, CIFAR-10 Batch 2:  Loss:     0.7271 Validation Accuracy: 0.572000\n",
      "Epoch 478, CIFAR-10 Batch 3:  Loss:     0.6653 Validation Accuracy: 0.573200\n",
      "Epoch 478, CIFAR-10 Batch 4:  Loss:     0.7287 Validation Accuracy: 0.570000\n",
      "Epoch 478, CIFAR-10 Batch 5:  Loss:     0.8049 Validation Accuracy: 0.575400\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     0.8731 Validation Accuracy: 0.569000\n",
      "Epoch 479, CIFAR-10 Batch 2:  Loss:     0.7355 Validation Accuracy: 0.572000\n",
      "Epoch 479, CIFAR-10 Batch 3:  Loss:     0.7095 Validation Accuracy: 0.573800\n",
      "Epoch 479, CIFAR-10 Batch 4:  Loss:     0.7176 Validation Accuracy: 0.576000\n",
      "Epoch 479, CIFAR-10 Batch 5:  Loss:     0.7830 Validation Accuracy: 0.577000\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     0.8790 Validation Accuracy: 0.571600\n",
      "Epoch 480, CIFAR-10 Batch 2:  Loss:     0.7184 Validation Accuracy: 0.573800\n",
      "Epoch 480, CIFAR-10 Batch 3:  Loss:     0.6885 Validation Accuracy: 0.577000\n",
      "Epoch 480, CIFAR-10 Batch 4:  Loss:     0.6968 Validation Accuracy: 0.574200\n",
      "Epoch 480, CIFAR-10 Batch 5:  Loss:     0.8001 Validation Accuracy: 0.574600\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     0.8915 Validation Accuracy: 0.571000\n",
      "Epoch 481, CIFAR-10 Batch 2:  Loss:     0.7267 Validation Accuracy: 0.574200\n",
      "Epoch 481, CIFAR-10 Batch 3:  Loss:     0.7030 Validation Accuracy: 0.576000\n",
      "Epoch 481, CIFAR-10 Batch 4:  Loss:     0.7075 Validation Accuracy: 0.575200\n",
      "Epoch 481, CIFAR-10 Batch 5:  Loss:     0.8104 Validation Accuracy: 0.576600\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     0.8843 Validation Accuracy: 0.576000\n",
      "Epoch 482, CIFAR-10 Batch 2:  Loss:     0.7224 Validation Accuracy: 0.573000\n",
      "Epoch 482, CIFAR-10 Batch 3:  Loss:     0.6680 Validation Accuracy: 0.573600\n",
      "Epoch 482, CIFAR-10 Batch 4:  Loss:     0.7122 Validation Accuracy: 0.574400\n",
      "Epoch 482, CIFAR-10 Batch 5:  Loss:     0.8233 Validation Accuracy: 0.577600\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     0.8632 Validation Accuracy: 0.572800\n",
      "Epoch 483, CIFAR-10 Batch 2:  Loss:     0.7357 Validation Accuracy: 0.574800\n",
      "Epoch 483, CIFAR-10 Batch 3:  Loss:     0.6657 Validation Accuracy: 0.577400\n",
      "Epoch 483, CIFAR-10 Batch 4:  Loss:     0.7158 Validation Accuracy: 0.570600\n",
      "Epoch 483, CIFAR-10 Batch 5:  Loss:     0.8146 Validation Accuracy: 0.573400\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     0.8615 Validation Accuracy: 0.570000\n",
      "Epoch 484, CIFAR-10 Batch 2:  Loss:     0.7439 Validation Accuracy: 0.571000\n",
      "Epoch 484, CIFAR-10 Batch 3:  Loss:     0.6610 Validation Accuracy: 0.577800\n",
      "Epoch 484, CIFAR-10 Batch 4:  Loss:     0.7328 Validation Accuracy: 0.570400\n",
      "Epoch 484, CIFAR-10 Batch 5:  Loss:     0.8279 Validation Accuracy: 0.573200\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     0.8605 Validation Accuracy: 0.570000\n",
      "Epoch 485, CIFAR-10 Batch 2:  Loss:     0.7133 Validation Accuracy: 0.571600\n",
      "Epoch 485, CIFAR-10 Batch 3:  Loss:     0.6534 Validation Accuracy: 0.576000\n",
      "Epoch 485, CIFAR-10 Batch 4:  Loss:     0.6998 Validation Accuracy: 0.576400\n",
      "Epoch 485, CIFAR-10 Batch 5:  Loss:     0.8149 Validation Accuracy: 0.573600\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     0.8840 Validation Accuracy: 0.566800\n",
      "Epoch 486, CIFAR-10 Batch 2:  Loss:     0.7304 Validation Accuracy: 0.568600\n",
      "Epoch 486, CIFAR-10 Batch 3:  Loss:     0.6515 Validation Accuracy: 0.577800\n",
      "Epoch 486, CIFAR-10 Batch 4:  Loss:     0.7138 Validation Accuracy: 0.572200\n",
      "Epoch 486, CIFAR-10 Batch 5:  Loss:     0.8131 Validation Accuracy: 0.571000\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     0.8644 Validation Accuracy: 0.571400\n",
      "Epoch 487, CIFAR-10 Batch 2:  Loss:     0.7221 Validation Accuracy: 0.574800\n",
      "Epoch 487, CIFAR-10 Batch 3:  Loss:     0.6875 Validation Accuracy: 0.579800\n",
      "Epoch 487, CIFAR-10 Batch 4:  Loss:     0.7004 Validation Accuracy: 0.568000\n",
      "Epoch 487, CIFAR-10 Batch 5:  Loss:     0.8226 Validation Accuracy: 0.573800\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     0.8802 Validation Accuracy: 0.567200\n",
      "Epoch 488, CIFAR-10 Batch 2:  Loss:     0.7096 Validation Accuracy: 0.572800\n",
      "Epoch 488, CIFAR-10 Batch 3:  Loss:     0.7074 Validation Accuracy: 0.577000\n",
      "Epoch 488, CIFAR-10 Batch 4:  Loss:     0.7030 Validation Accuracy: 0.575000\n",
      "Epoch 488, CIFAR-10 Batch 5:  Loss:     0.8239 Validation Accuracy: 0.571600\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     0.8850 Validation Accuracy: 0.569200\n",
      "Epoch 489, CIFAR-10 Batch 2:  Loss:     0.7333 Validation Accuracy: 0.572600\n",
      "Epoch 489, CIFAR-10 Batch 3:  Loss:     0.6667 Validation Accuracy: 0.577400\n",
      "Epoch 489, CIFAR-10 Batch 4:  Loss:     0.6978 Validation Accuracy: 0.570200\n",
      "Epoch 489, CIFAR-10 Batch 5:  Loss:     0.8092 Validation Accuracy: 0.569800\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     0.8709 Validation Accuracy: 0.569600\n",
      "Epoch 490, CIFAR-10 Batch 2:  Loss:     0.7288 Validation Accuracy: 0.570800\n",
      "Epoch 490, CIFAR-10 Batch 3:  Loss:     0.6739 Validation Accuracy: 0.576000\n",
      "Epoch 490, CIFAR-10 Batch 4:  Loss:     0.6901 Validation Accuracy: 0.571000\n",
      "Epoch 490, CIFAR-10 Batch 5:  Loss:     0.8238 Validation Accuracy: 0.575800\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     0.8743 Validation Accuracy: 0.572800\n",
      "Epoch 491, CIFAR-10 Batch 2:  Loss:     0.7145 Validation Accuracy: 0.570600\n",
      "Epoch 491, CIFAR-10 Batch 3:  Loss:     0.6815 Validation Accuracy: 0.575600\n",
      "Epoch 491, CIFAR-10 Batch 4:  Loss:     0.7110 Validation Accuracy: 0.571800\n",
      "Epoch 491, CIFAR-10 Batch 5:  Loss:     0.8265 Validation Accuracy: 0.574600\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     0.9072 Validation Accuracy: 0.566800\n",
      "Epoch 492, CIFAR-10 Batch 2:  Loss:     0.7049 Validation Accuracy: 0.571800\n",
      "Epoch 492, CIFAR-10 Batch 3:  Loss:     0.6885 Validation Accuracy: 0.577000\n",
      "Epoch 492, CIFAR-10 Batch 4:  Loss:     0.7020 Validation Accuracy: 0.575600\n",
      "Epoch 492, CIFAR-10 Batch 5:  Loss:     0.8260 Validation Accuracy: 0.571800\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     0.8835 Validation Accuracy: 0.569800\n",
      "Epoch 493, CIFAR-10 Batch 2:  Loss:     0.7256 Validation Accuracy: 0.569000\n",
      "Epoch 493, CIFAR-10 Batch 3:  Loss:     0.6793 Validation Accuracy: 0.574400\n",
      "Epoch 493, CIFAR-10 Batch 4:  Loss:     0.7036 Validation Accuracy: 0.576200\n",
      "Epoch 493, CIFAR-10 Batch 5:  Loss:     0.8278 Validation Accuracy: 0.572800\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     0.8979 Validation Accuracy: 0.569800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494, CIFAR-10 Batch 2:  Loss:     0.7112 Validation Accuracy: 0.571600\n",
      "Epoch 494, CIFAR-10 Batch 3:  Loss:     0.6778 Validation Accuracy: 0.578400\n",
      "Epoch 494, CIFAR-10 Batch 4:  Loss:     0.7189 Validation Accuracy: 0.571000\n",
      "Epoch 494, CIFAR-10 Batch 5:  Loss:     0.8147 Validation Accuracy: 0.574600\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     0.8750 Validation Accuracy: 0.569000\n",
      "Epoch 495, CIFAR-10 Batch 2:  Loss:     0.7168 Validation Accuracy: 0.573600\n",
      "Epoch 495, CIFAR-10 Batch 3:  Loss:     0.6651 Validation Accuracy: 0.575400\n",
      "Epoch 495, CIFAR-10 Batch 4:  Loss:     0.6928 Validation Accuracy: 0.572800\n",
      "Epoch 495, CIFAR-10 Batch 5:  Loss:     0.8133 Validation Accuracy: 0.572800\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     0.8668 Validation Accuracy: 0.567600\n",
      "Epoch 496, CIFAR-10 Batch 2:  Loss:     0.7016 Validation Accuracy: 0.574400\n",
      "Epoch 496, CIFAR-10 Batch 3:  Loss:     0.6522 Validation Accuracy: 0.571800\n",
      "Epoch 496, CIFAR-10 Batch 4:  Loss:     0.6864 Validation Accuracy: 0.575400\n",
      "Epoch 496, CIFAR-10 Batch 5:  Loss:     0.7954 Validation Accuracy: 0.572800\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     0.8780 Validation Accuracy: 0.569200\n",
      "Epoch 497, CIFAR-10 Batch 2:  Loss:     0.7365 Validation Accuracy: 0.566600\n",
      "Epoch 497, CIFAR-10 Batch 3:  Loss:     0.6921 Validation Accuracy: 0.575400\n",
      "Epoch 497, CIFAR-10 Batch 4:  Loss:     0.6869 Validation Accuracy: 0.572000\n",
      "Epoch 497, CIFAR-10 Batch 5:  Loss:     0.8080 Validation Accuracy: 0.576800\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     0.8775 Validation Accuracy: 0.572000\n",
      "Epoch 498, CIFAR-10 Batch 2:  Loss:     0.7259 Validation Accuracy: 0.573000\n",
      "Epoch 498, CIFAR-10 Batch 3:  Loss:     0.6896 Validation Accuracy: 0.576600\n",
      "Epoch 498, CIFAR-10 Batch 4:  Loss:     0.6875 Validation Accuracy: 0.566600\n",
      "Epoch 498, CIFAR-10 Batch 5:  Loss:     0.8563 Validation Accuracy: 0.571200\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     0.8834 Validation Accuracy: 0.572000\n",
      "Epoch 499, CIFAR-10 Batch 2:  Loss:     0.7167 Validation Accuracy: 0.571600\n",
      "Epoch 499, CIFAR-10 Batch 3:  Loss:     0.6637 Validation Accuracy: 0.579000\n",
      "Epoch 499, CIFAR-10 Batch 4:  Loss:     0.7249 Validation Accuracy: 0.571600\n",
      "Epoch 499, CIFAR-10 Batch 5:  Loss:     0.8034 Validation Accuracy: 0.573600\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     0.8968 Validation Accuracy: 0.568000\n",
      "Epoch 500, CIFAR-10 Batch 2:  Loss:     0.7061 Validation Accuracy: 0.575400\n",
      "Epoch 500, CIFAR-10 Batch 3:  Loss:     0.6583 Validation Accuracy: 0.572800\n",
      "Epoch 500, CIFAR-10 Batch 4:  Loss:     0.6875 Validation Accuracy: 0.577400\n",
      "Epoch 500, CIFAR-10 Batch 5:  Loss:     0.8091 Validation Accuracy: 0.572600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.5724881329113924\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw6G76dSTQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b54d4feb8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
